<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye Movement Data Collection & Cognitive Assessment</title>
    <!-- TensorFlow.js -->
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <!-- WebGazer for Eye Tracking -->
    <script defer src="https://cdn.jsdelivr.net/npm/webgazer"></script>
    <style>
        /* Basic Reset */
        body, html {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            height: 100%;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f0f2f5;
            color: #333;
            display: flex;
            flex-direction: column;
            justify-content: flex-start;
            align-items: center;
        }

        /* Container */
        .container {
            width: 90%;
            max-width: 1200px;
            text-align: center;
            padding: 20px;
            margin-top: 20px;
        }

        /* Header Styling */
        header h1 {
            font-size: 2em;
            font-weight: 700;
            color: #007BFF;
            margin-bottom: 20px;
            border-bottom: 2px solid #61dafb;
            padding-bottom: 10px;
        }

        /* Central Camera Frame */
        #camera-frame {
            position: relative;
            margin: 20px auto;
            width: 200px;
            height: 200px;
            border-radius: 50%;
            overflow: hidden;
            border: 4px solid #61dafb;
            background-color: #ffffff;
            box-shadow: 0 0 15px rgba(0, 0, 0, 0.3);
        }

        #webcamVideo {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        /* Task Container */
        #task-container {
            margin: 20px 0;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            gap: 10px;
        }

        .ring {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            border: 3px solid black;
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 1.5em;
            cursor: pointer;
            transition: transform 0.2s, background-color 0.2s;
        }

        .ring:hover {
            transform: scale(1.1);
        }

        .target-ring-upward {
            border-color: red;
            font-size: 2em;
        }

        .distractor-ring {
            border-color: black;
        }

        .target-ring-color {
            border-color: red;
            background-color: #ffcccc;
        }

        /* Calibration Message */
        #calibrationMessage {
            margin-top: 10px;
            color: #007BFF;
            font-size: 1.2em;
            text-shadow: 1px 1px 5px rgba(0, 0, 0, 0.3);
        }

        /* Footer Styling */
        footer {
            width: 100%;
            background: #ffffff;
            color: #777;
            padding: 15px;
            border-radius: 20px 20px 0 0;
            font-size: 0.9em;
            text-align: center;
            box-shadow: 0 -5px 15px rgba(0, 0, 0, 0.2);
            position: fixed;
            bottom: 0;
        }

        /* Start Button */
        #startButton {
            padding: 10px 20px;
            font-size: 1.2em;
            background-color: #28a745;
            color: #ffffff;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
            margin-bottom: 20px;
        }

        #startButton:hover {
            background-color: #218838;
        }

        /* Trial Information */
        #trialInfo {
            margin-top: 15px;
            font-size: 1.1em;
            color: #555;
        }

        /* Drawing Upload Section */
        #drawing-section {
            margin: 20px 0;
            display: none;
            flex-direction: column;
            align-items: center;
        }

        #drawingUpload {
            margin-top: 10px;
        }

        #uploadButton {
            padding: 8px 16px;
            font-size: 1em;
            background-color: #17a2b8;
            color: #ffffff;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
            margin-top: 10px;
        }

        #uploadButton:hover {
            background-color: #138496;
        }

        /* Results Section */
        #results-section {
            margin: 20px 0;
            display: none;
            flex-direction: column;
            align-items: center;
        }

        #results-message {
            font-size: 1.2em;
            color: #28a745;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .ring {
                width: 40px;
                height: 40px;
                font-size: 1em;
            }

            #camera-frame {
                width: 150px;
                height: 150px;
            }

            #startButton {
                font-size: 1em;
                padding: 8px 16px;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <header>
            <h1>Eye Movement Data Collection & Cognitive Assessment</h1>
        </header>

        <!-- Central Camera Frame -->
        <div id="camera-frame">
            <video id="webcamVideo" autoplay playsinline></video>
        </div>

        <!-- Start Button -->
        <button id="startButton">Start Task</button>

        <!-- Trial Information -->
        <div id="trialInfo"></div>

        <!-- Task Container -->
        <div id="task-container">
            <!-- Dynamically generated visual search task or memory images will appear here -->
        </div>

        <!-- Calibration Message -->
        <div id="calibrationMessage">Press "Start Task" to begin.</div>

        <!-- Drawing Upload Section -->
        <div id="drawing-section">
            <h2>Drawing Task</h2>
            <p>Please draw the images you memorized on a piece of paper.</p>
            <input type="file" id="drawingUpload" accept="image/*">
            <button id="uploadButton">Upload Drawing</button>
            <div id="uploadStatus"></div>
        </div>

        <!-- Results Section -->
        <div id="results-section">
            <h2>Assessment Complete</h2>
            <p id="results-message">Processing your data...</p>
        </div>
    </div>

    <footer>
        <p>&copy; 2024 Eye Movement Research</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const taskContainer = document.getElementById('task-container');
            const calibrationMessage = document.getElementById('calibrationMessage');
            const startButton = document.getElementById('startButton');
            const trialInfo = document.getElementById('trialInfo');
            const webcamVideo = document.getElementById('webcamVideo');
            const drawingSection = document.getElementById('drawing-section');
            const drawingUpload = document.getElementById('drawingUpload');
            const uploadButton = document.getElementById('uploadButton');
            const uploadStatus = document.getElementById('uploadStatus');
            const resultsSection = document.getElementById('results-section');
            const resultsMessage = document.getElementById('results-message');

            const searchTimeLimit = 60000; // 60 seconds per trial
            let currentTrial = 0;
            let trials = [];
            let targetPositions = []; // To store target positions for accuracy calculation

            // Configuration based on the research paper
            const taskTypes = ['serial', 'popout'];
            const numberOfRingsOptions = [4, 48];
            const trialsPerCombination = 10; // Total of 40 trials

            // Initialize trials
            for (let task of taskTypes) {
                for (let numRings of numberOfRingsOptions) {
                    for (let i = 0; i < trialsPerCombination; i++) {
                        trials.push({
                            taskType: task,
                            numberOfRings: numRings,
                            reactionTime: null, // To store reaction time
                            gazeData: [] // To store gaze data for this trial
                        });
                    }
                }
            }

            // Shuffle trials to randomize the order
            shuffleArray(trials);

            // Array to store all gaze data
            let allGazeData = [];

            let timer;
            let trialStartTime;

            // Start Button Event Listener
            startButton.addEventListener('click', function () {
                startButton.style.display = 'none';
                startCamera()
                    .then(() => {
                        calibrationMessage.textContent = 'Camera started. Preparing to start tasks...';
                        setTimeout(startVisualMemoryTask, 2000); // Delay before starting memory task
                    })
                    .catch(error => {
                        console.error('Error starting camera:', error);
                        calibrationMessage.textContent = 'Error: Unable to access camera.';
                        startButton.style.display = 'block';
                    });
            });

            // Start the camera
            async function startCamera() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    webcamVideo.srcObject = stream;
                    console.log("Camera started");
                } catch (error) {
                    throw error;
                }
            }

            // Stop the camera
            function stopCamera() {
                const stream = webcamVideo.srcObject;
                if (stream) {
                    const tracks = stream.getTracks();
                    tracks.forEach(track => track.stop());
                    webcamVideo.srcObject = null;
                    console.log("Camera stopped");
                }
            }

            // Visual Memory Task Images
            const memoryImages = [
                'image1.jpg', // Replace with your actual image paths or URLs
                'image2.jpg',
                'image3.jpg',
                'image4.jpg'
            ];

            // Start Visual Memory Task
            function startVisualMemoryTask() {
                trialInfo.textContent = `Visual Memory Task: Memorize the images for 10 seconds each.`;
                displayMemoryImages(0);
            }

            // Display Memory Images Sequentially
            function displayMemoryImages(index) {
                if (index >= memoryImages.length) {
                    calibrationMessage.textContent = 'Visual Memory Task Completed.';
                    showDrawingSection();
                    return;
                }

                // Display the image
                taskContainer.innerHTML = `<img src="${memoryImages[index]}" alt="Memory Image" style="max-width: 100%; max-height: 500px;">`;
                calibrationMessage.textContent = `Memorize the image (${index + 1} of ${memoryImages.length}) for 10 seconds.`;

                // Start recording gaze data
                trials.push({
                    taskType: 'memory',
                    numberOfRings: 0,
                    reactionTime: null,
                    gazeData: [],
                    image: memoryImages[index]
                });

                // Start timer for 10 seconds
                setTimeout(() => {
                    displayMemoryImages(index + 1);
                }, 10000);
            }

            // Show Drawing Upload Section
            function showDrawingSection() {
                taskContainer.innerHTML = '';
                calibrationMessage.textContent = 'Please draw the images you memorized on a piece of paper.';
                drawingSection.style.display = 'flex';
            }

            // Handle Drawing Upload
            uploadButton.addEventListener('click', function () {
                const files = drawingUpload.files;
                if (files.length === 0) {
                    uploadStatus.textContent = 'Please select a drawing to upload.';
                    uploadStatus.style.color = 'red';
                    return;
                }

                const file = files[0];
                const reader = new FileReader();
                reader.onload = function (e) {
                    const imgData = e.target.result;
                    uploadStatus.innerHTML = `<p style="color: green;">Drawing uploaded successfully.</p><img src="${imgData}" alt="Uploaded Drawing" style="max-width: 300px; max-height: 300px;">`;
                    // Implement drawing scoring here
                    const drawingScore = scoreDrawing(file); // Placeholder function
                    calibrationMessage.textContent = `Drawing Score: ${drawingScore}/5`;
                    // Proceed to Visual Search Tasks after a short delay
                    setTimeout(startVisualSearchTask, 3000);
                };
                reader.readAsDataURL(file);
            });

            // Placeholder Function for Drawing Scoring
            function scoreDrawing(file) {
                // Implement your drawing scoring logic here
                // For demonstration, returning a random score between 0 and 5
                return Math.floor(Math.random() * 6);
            }

            // Start Visual Search Task
            function startVisualSearchTask() {
                taskContainer.innerHTML = '';
                calibrationMessage.textContent = 'Starting Visual Search Tasks.';
                setTimeout(startNextTrial, 2000); // Short delay before starting trials
            }

            // Start the next trial
            function startNextTrial() {
                if (currentTrial >= trials.length) {
                    endExperiment();
                    return;
                }

                const trial = trials[currentTrial];
                currentTrial++;

                if (trial.taskType === 'memory') {
                    // Skip memory trials in search
                    startNextTrial();
                    return;
                }

                trialInfo.textContent = `Trial ${currentTrial} of ${trials.length}: ${capitalizeFirstLetter(trial.taskType)} Search with ${trial.numberOfRings} Rings`;

                createSearchTask(trial.taskType, trial.numberOfRings, currentTrial - 1);
                calibrationMessage.textContent = 'Please find the target as quickly as possible.';
                trialStartTime = Date.now();

                startTimer(currentTrial - 1);
            }

            // Create Search Task
            function createSearchTask(taskType, numberOfRings, trialIndex) {
                taskContainer.innerHTML = '';
                const targetPosition = Math.floor(Math.random() * numberOfRings);
                targetPositions[trialIndex] = targetPosition; // Store target position for accuracy

                for (let i = 0; i < numberOfRings; i++) {
                    const ring = document.createElement('div');
                    ring.classList.add('ring');

                    if (taskType === 'serial') {
                        // Serial Search: Target has upward orientation, distractors downward
                        if (i === targetPosition) {
                            ring.classList.add('target-ring-upward');
                            ring.textContent = '↑'; // Upward
                            ring.style.transform = 'rotate(0deg)';
                        } else {
                            ring.classList.add('distractor-ring');
                            ring.textContent = '↓'; // Downward
                            ring.style.transform = 'rotate(180deg)';
                        }
                    } else if (taskType === 'popout') {
                        // Pop-out Search: Target has different color, distractors same color
                        if (i === targetPosition) {
                            ring.classList.add('target-ring-color');
                            ring.textContent = 'O'; // Red
                        } else {
                            ring.classList.add('distractor-ring');
                            ring.textContent = 'O'; // Black
                        }
                    }

                    taskContainer.appendChild(ring);
                    ring.addEventListener('click', onRingClick.bind(null, i === targetPosition, trialIndex));
                }
            }

            // Handle Ring Click
            function onRingClick(isTarget, trialIndex) {
                if (isTarget) {
                    clearTimeout(timer);
                    const reactionTime = Date.now() - trialStartTime;
                    calibrationMessage.textContent = `Correct! Reaction Time: ${reactionTime} ms. Preparing next trial...`;

                    // Store trial data
                    trials[trialIndex].reactionTime = reactionTime;
                    trials[trialIndex].gazeData = gazeData.slice(); // Copy current gaze data
                    allGazeData = allGazeData.concat(gazeData); // Aggregate all gaze data
                    gazeData = []; // Reset for next trial

                    setTimeout(startNextTrial, 2000);
                } else {
                    calibrationMessage.textContent = 'Incorrect target. Try again!';
                }
            }

            // Start Timer for Trial
            function startTimer(trialIndex) {
                timer = setTimeout(() => {
                    calibrationMessage.textContent = 'Time is up! Proceeding to the next trial...';
                    // Store trial data with null reaction time
                    trials[trialIndex].reactionTime = null;
                    trials[trialIndex].gazeData = gazeData.slice(); // Copy current gaze data
                    allGazeData = allGazeData.concat(gazeData); // Aggregate all gaze data
                    gazeData = []; // Reset for next trial

                    setTimeout(startNextTrial, 2000);
                }, searchTimeLimit);
            }

            // End Experiment
            function endExperiment() {
                taskContainer.innerHTML = '';
                calibrationMessage.textContent = 'Data Collection complete. Processing results...';
                trialInfo.textContent = '';
                stopCamera();
                showResultsSection();
            }

            // Show Results Section and Process Data
            function showResultsSection() {
                resultsSection.style.display = 'flex';
                resultsMessage.textContent = 'Processing your data... Please wait.';

                // Extract features from allGazeData
                const features = extractFeatures(allGazeData, trials, targetPositions);

                // Make prediction using TensorFlow.js model
                makePrediction(features);
            }

            // Shuffle array in-place using Fisher-Yates algorithm
            function shuffleArray(array) {
                for (let i = array.length - 1; i > 0; i--) {
                    const j = Math.floor(Math.random() * (i + 1));
                    [array[i], array[j]] = [array[j], array[i]];
                }
            }

            // Initialize WebGazer for Eye Tracking
            webgazer.setGazeListener(function (data, elapsedTime) {
                if (data == null) {
                    return;
                }
                // Store gaze data with timestamp
                gazeData.push({
                    x: data.x,
                    y: data.y,
                    timestamp: elapsedTime,
                    pupilSize: data.pupil || null // Assuming WebGazer provides pupil size
                });
            }).begin();

            // Disable WebGazer’s built-in UI
            webgazer.showVideo(false).showFaceOverlay(false).showFaceFeedbackBox(false);

            // Feature Extraction Function
            function extractFeatures(allGazeData, trials, targetPositions) {
                // Compute the six features as per your study
                const pupilSizes = allGazeData.map(d => d.pupilSize).filter(p => p !== null);
                const pupilSizeModulation = computePupilSizeModulation(pupilSizes);

                const saccadicLatencies = trials.filter(t => t.taskType !== 'memory').map((trial, index) => {
                    return computeSaccadicLatency(trial.gazeData);
                }).filter(latency => latency !== null);
                const averageSaccadicLatency = saccadicLatencies.length > 0 ? (saccadicLatencies.reduce((a, b) => a + b, 0) / saccadicLatencies.length) : 0;

                const smoothPursuitGain = computeSmoothPursuitGain(allGazeData); // Needs proper implementation

                const saccadicAccuracies = trials.filter(t => t.taskType !== 'memory').map((trial, index) => {
                    return computeSaccadicAccuracy(trial.gazeData, targetPositions[index]);
                }).filter(acc => acc !== null);
                const averageSaccadicAccuracy = saccadicAccuracies.length > 0 ? (saccadicAccuracies.reduce((a, b) => a + b, 0) / saccadicAccuracies.length) : 0;

                const fixationDurations = allGazeData.map(d => d.fixationDuration).filter(d => d !== null);
                const averageFixationDuration = fixationDurations.length > 0 ? (fixationDurations.reduce((a, b) => a + b, 0) / fixationDurations.length) : 0;

                const searchTimeSerial = computeSearchTimeSerial(trials, 'serial'); // Needs proper implementation

                return [
                    pupilSizeModulation,
                    averageSaccadicLatency,
                    smoothPursuitGain,
                    averageSaccadicAccuracy,
                    averageFixationDuration,
                    searchTimeSerial
                ];
            }

            // Feature Extraction Implementations
            function computePupilSizeModulation(pupilSizes) {
                // Calculate the standard deviation of pupil sizes
                if (pupilSizes.length === 0) return 0;
                const mean = pupilSizes.reduce((a, b) => a + b, 0) / pupilSizes.length;
                const variance = pupilSizes.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / pupilSizes.length;
                return Math.sqrt(variance);
            }

            function computeSaccadicLatency(gazeData) {
                // Define saccade as a rapid movement between two points
                // Here, we consider a saccade if the movement between consecutive points exceeds a threshold
                const velocityThreshold = 1000; // pixels per second, adjust as needed
                for (let i = 1; i < gazeData.length; i++) {
                    const dt = (gazeData[i].timestamp - gazeData[i - 1].timestamp) / 1000; // seconds
                    const dx = gazeData[i].x - gazeData[i - 1].x;
                    const dy = gazeData[i].y - gazeData[i - 1].y;
                    const distance = Math.sqrt(dx * dx + dy * dy);
                    const velocity = distance / dt;
                    if (velocity > velocityThreshold) {
                        return gazeData[i].timestamp; // Return the timestamp of the first saccade
                    }
                }
                return null; // No saccade detected
            }

            function computeSmoothPursuitGain(gazeData) {
                // Placeholder: Implement based on your specific definition
                // Smooth pursuit requires target movement data, which is not present in static tasks
                // Returning 0 as placeholder
                return 0;
            }

            function computeSaccadicAccuracy(gazeData, targetPosition) {
                if (!targetPosition) return 0;
                // Assume targetPosition is the index; need to map it to screen coordinates
                // For simplicity, we'll calculate distance from the center
                const screenCenterX = window.innerWidth / 2;
                const screenCenterY = window.innerHeight / 2;
                const targetX = mapPositionToCoordinates(targetPosition, trials[currentTrial - 1].numberOfRings).x;
                const targetY = mapPositionToCoordinates(targetPosition, trials[currentTrial - 1].numberOfRings).y;

                const lastGaze = gazeData[gazeData.length - 1];
                const distance = Math.sqrt(Math.pow(lastGaze.x - targetX, 2) + Math.pow(lastGaze.y - targetY, 2));
                return distance < 50 ? 1 : 0; // 1 for accurate, 0 otherwise
            }

            function computeFixationDuration(allGazeData) {
                // Identify fixations as periods with minimal movement
                // For simplicity, we'll calculate the average duration between gaze points that are close together
                let fixationDurations = [];
                let currentFixationStart = null;
                let currentFixationEnd = null;
                const fixationThreshold = 50; // pixels
                const minFixationDuration = 100; // milliseconds

                for (let i = 0; i < allGazeData.length; i++) {
                    const point = allGazeData[i];
                    if (i === 0) {
                        currentFixationStart = point.timestamp;
                        currentFixationEnd = point.timestamp;
                        continue;
                    }

                    const prevPoint = allGazeData[i - 1];
                    const distance = Math.sqrt(Math.pow(point.x - prevPoint.x, 2) + Math.pow(point.y - prevPoint.y, 2));

                    if (distance < fixationThreshold) {
                        currentFixationEnd = point.timestamp;
                    } else {
                        const duration = currentFixationEnd - currentFixationStart;
                        if (duration >= minFixationDuration) {
                            fixationDurations.push(duration);
                        }
                        currentFixationStart = point.timestamp;
                        currentFixationEnd = point.timestamp;
                    }
                }

                // Add the last fixation
                const finalDuration = currentFixationEnd - currentFixationStart;
                if (finalDuration >= minFixationDuration) {
                    fixationDurations.push(finalDuration);
                }

                if (fixationDurations.length === 0) return 0;
                const averageFixationDuration = fixationDurations.reduce((a, b) => a + b, 0) / fixationDurations.length;
                return averageFixationDuration;
            }

            function computeSearchTimeSerial(trials, taskType) {
                // Calculate the average reaction time for serial search tasks
                const serialTrials = trials.filter(trial => trial.taskType === 'serial' && trial.reactionTime !== null);
                if (serialTrials.length === 0) return 0;
                const totalReactionTime = serialTrials.reduce((a, b) => a + b.reactionTime, 0);
                return totalReactionTime / serialTrials.length;
            }

            // Map ring index to screen coordinates (simplified)
            function mapPositionToCoordinates(index, totalRings) {
                const angle = (2 * Math.PI / totalRings) * index;
                const radius = 200; // Distance from center in pixels
                const centerX = window.innerWidth / 2;
                const centerY = window.innerHeight / 2;
                const x = centerX + radius * Math.cos(angle);
                const y = centerY + radius * Math.sin(angle);
                return { x, y };
            }

            // Make Prediction using TensorFlow.js Model
            async function makePrediction(features) {
                try {
                    console.log("Loading model...");
                    const model = await tf.loadLayersModel('./model.json'); // Ensure the model.json is correctly hosted
                    console.log('Model loaded successfully');

                    // Normalize or preprocess features as required by your model
                    // Example: Assuming features need to be normalized between 0 and 1
                    const normalizedFeatures = features.map(feature => feature / 100); // Adjust normalization as needed

                    const inputTensor = tf.tensor2d([normalizedFeatures]);

                    // Make prediction
                    const prediction = model.predict(inputTensor);
                    const predictedClass = prediction.argMax(1).dataSync()[0]; // Assuming classification

                    console.log("Predicted value:", predictedClass);

                    // Display prediction result
                    displayPrediction(predictedClass);
                } catch (error) {
                    console.error('Prediction error:', error);
                    resultsMessage.textContent = 'An error occurred during prediction.';
                }
            }

            // Display Prediction Result
            function displayPrediction(predictedClass) {
                if (predictedClass === 1) { // Assuming 1 indicates high risk
                    resultsMessage.innerHTML = `<p style="color: red;"><strong>High Risk of Alzheimer's Detected.</strong></p>`;
                } else { // Assuming 0 indicates low risk
                    resultsMessage.innerHTML = `<p style="color: green;"><strong>No Significant Risk Detected.</strong></p>`;
                }
            }

            // Helper Function to Capitalize First Letter
            function capitalizeFirstLetter(string) {
                return string.charAt(0).toUpperCase() + string.slice(1);
            }

            // Feature Extraction and Data Storage (Called after each trial)
            function extractFeaturesAndStore(reactionTime) {
                // Implement as per your specific requirements
                // For example, store reactionTime and associated gazeData
                // Here, we are storing reactionTime within the trials array
                // Gaze data is already being collected in the gazeData array
            }

            // Ensure data is saved when the page is unloaded
            window.addEventListener('beforeunload', function (e) {
                // Implement data saving logic here, such as sending data to a server
                // For security reasons, browsers may restrict certain actions during beforeunload
            });
        });
    </script>
</body>
</html>
