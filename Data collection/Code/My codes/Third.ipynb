{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "OgE6dNoHxfpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices\n",
        "LEFT_EYE_INDICES = [33, 133, 160, 159, 158, 157, 173, 153, 144, 145, 153]\n",
        "RIGHT_EYE_INDICES = [362, 263, 387, 386, 385, 384, 398, 382, 381, 380, 374]\n",
        "\n",
        "# Initialize variables for tracking\n",
        "previous_center = None\n",
        "speed = 0\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to calculate the center of the eye\n",
        "def calculate_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "# Function to display video frames in Colab\n",
        "def display_frame(image):\n",
        "    # Convert BGR to RGB\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # Convert to PIL Image\n",
        "    pil_img = Image.fromarray(image_rgb)\n",
        "    # Display the image\n",
        "    display(pil_img)\n",
        "\n",
        "# Callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    # Decode the Base64 image\n",
        "    header, encoded = dataURL.split(\",\", 1)\n",
        "    data = b64decode(encoded)\n",
        "    img = Image.open(io.BytesIO(data))\n",
        "    img = img.convert('RGB')\n",
        "    img = np.array(img)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    with lock:\n",
        "        frames.append(img)\n",
        "\n",
        "# Register the callback\n",
        "from google.colab import output\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 100);  // Send frame every 100ms\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Function to process frames and display results\n",
        "def process_frames():\n",
        "    global previous_center, speed\n",
        "    while True:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center\n",
        "                    cv2.circle(frame, eye_center, 5, (0, 255, 255), -1)\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        speed = math.sqrt(dx**2 + dy**2)\n",
        "                    previous_center = eye_center\n",
        "\n",
        "                    # Display speed on the frame\n",
        "                    cv2.putText(frame, f'Speed: {speed:.2f}', (10, 30),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "            # Display the processed frame\n",
        "            display_frame(frame)\n",
        "            # Clear previous output\n",
        "            from IPython.display import clear_output\n",
        "            clear_output(wait=True)\n",
        "        time.sleep(0.1)  # Adjust the sleep time as needed\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "thread = threading.Thread(target=process_frames)\n",
        "thread.start()\n",
        "\n",
        "# To stop the processing, interrupt the kernel (e.g., by clicking the stop button)\n"
      ],
      "metadata": {
        "id": "s3TTl5C3wQS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "First"
      ],
      "metadata": {
        "id": "AXyF4Rm8xjvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices\n",
        "LEFT_EYE_INDICES = [33, 133, 160, 159, 158, 157, 173, 153, 144, 145, 153]\n",
        "RIGHT_EYE_INDICES = [362, 263, 387, 386, 385, 384, 398, 382, 381, 380, 374]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([hbox, speed_label])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position\n",
        "    amplification_factor = 20  # Increased amplification for clearer movement\n",
        "    while True:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.zeros((224, 224, 3), dtype=np.uint8)  # Black background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Update yellow_dot_position based on movement delta\n",
        "                    yellow_dot_position[0] += int(dx * amplification_factor)\n",
        "                    yellow_dot_position[1] += int(dy * amplification_factor)\n",
        "\n",
        "                    # Clip the yellow_dot_position within the frame\n",
        "                    yellow_dot_position[0] = max(0, min(223, yellow_dot_position[0]))\n",
        "                    yellow_dot_position[1] = max(0, min(223, yellow_dot_position[1]))\n",
        "\n",
        "                    # Draw the yellow dot on the separate frame\n",
        "                    cv2.circle(yellow_dot_frame, (yellow_dot_position[0], yellow_dot_position[1]), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update speed info\n",
        "            speed_label.value = speed_info\n",
        "\n",
        "        # Control frame rate (currently 20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Note:\n",
        "# To stop the processing, interrupt the Colab kernel by clicking the \"Stop\" button.\n"
      ],
      "metadata": {
        "id": "cyPwkbUtH_o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second"
      ],
      "metadata": {
        "id": "J6h12QjTg7Jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "blink_label = widgets.Label(value=\"Blink Count: 0\")                     # Blink count\n",
        "fixation_label = widgets.Label(value=\"Fixation Duration: 0.00 sec\")    # Fixation duration\n",
        "pupil_label = widgets.Label(value=\"Pupil Diameter: 0.00 mm\")            # Pupil diameter\n",
        "gaze_label = widgets.Label(value=\"Gaze Deviation: 0.00 degrees\")       # Gaze deviation\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([hbox, speed_label, blink_label, fixation_label, pupil_label, gaze_label])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag, fixation_start_time, fixation_duration, data_records\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "    while True:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels\n",
        "            speed_label.value = speed_info\n",
        "            blink_label.value = f\"Blink Count: {blink_count}\"\n",
        "            fixation_label.value = fixation_info\n",
        "            pupil_label.value = f\"Pupil Diameter: {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"Gaze Deviation: {gaze_deviation:.2f} degrees\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the kernel is interrupted\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "4qHzrfWWg2XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third"
      ],
      "metadata": {
        "id": "KZ0ff1EbJ7F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "blink_label = widgets.Label(value=\"Blink Count: 0\")                     # Blink count\n",
        "fixation_label = widgets.Label(value=\"Fixation Duration: 0.00 sec\")    # Fixation duration\n",
        "pupil_label = widgets.Label(value=\"Pupil Diameter: 0.00 mm\")            # Pupil diameter\n",
        "gaze_label = widgets.Label(value=\"Gaze Deviation: 0.00 degrees\")       # Gaze deviation\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\", button_style='danger')\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([hbox, speed_label, blink_label, fixation_label, pupil_label, gaze_label, stop_button])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag, fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels\n",
        "            speed_label.value = speed_info\n",
        "            blink_label.value = f\"Blink Count: {blink_count}\"\n",
        "            fixation_label.value = fixation_info\n",
        "            pupil_label.value = f\"Pupil Diameter: {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"Gaze Deviation: {gaze_deviation:.2f} degrees\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "ujixL8GEJ9Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forth"
      ],
      "metadata": {
        "id": "09kGlF6JNMi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "saccade_start_time = None\n",
        "saccadic_latency = 0\n",
        "smooth_pursuit_gain = 0\n",
        "search_time_start = None\n",
        "total_search_time = 0\n",
        "target_search_count = 0\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "def calculate_smooth_pursuit_gain(eye_center, previous_center, width, height):\n",
        "    if previous_center is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate movement distance\n",
        "    eye_movement = math.sqrt((eye_center[0] - previous_center[0])**2 + (eye_center[1] - previous_center[1])**2)\n",
        "    # Approximate target velocity using movement (can be improved with actual target data)\n",
        "    target_movement = math.sqrt(width**2 + height**2) / 60  # Assuming a screen-sized target moving at 60Hz\n",
        "    return eye_movement / target_movement\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "blink_label = widgets.Label(value=\"Blink Count: 0\")                     # Blink count\n",
        "fixation_label = widgets.Label(value=\"Fixation Duration: 0.00 sec\")    # Fixation duration\n",
        "pupil_label = widgets.Label(value=\"Pupil Diameter: 0.00 mm\")            # Pupil diameter\n",
        "gaze_label = widgets.Label(value=\"Gaze Deviation: 0.00 degrees\")       # Gaze deviation\n",
        "latency_label = widgets.Label(value=\"Saccadic Latency: 0 ms\")           # Saccadic latency\n",
        "smooth_pursuit_label = widgets.Label(value=\"Smooth Pursuit Gain: 0.00\") # Smooth pursuit gain\n",
        "search_time_label = widgets.Label(value=\"Search Time: 0 ms\")            # Search time\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\", button_style='danger')\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([hbox, speed_label, blink_label, fixation_label, pupil_label, gaze_label, latency_label, smooth_pursuit_label, search_time_label, stop_button])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag, fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global saccade_start_time, saccadic_latency, smooth_pursuit_gain, search_time_start, total_search_time, target_search_count\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Search Time in Serial Search\n",
        "                    if search_time_start is None:\n",
        "                        search_time_start = current_time\n",
        "                    else:\n",
        "                        total_search_time = (current_time - search_time_start) * 1000  # in ms\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Search_Time_ms\": total_search_time\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels\n",
        "            speed_label.value = speed_info\n",
        "            blink_label.value = f\"Blink Count: {blink_count}\"\n",
        "            fixation_label.value = fixation_info\n",
        "            pupil_label.value = f\"Pupil Diameter: {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"Gaze Deviation: {gaze_deviation:.2f} degrees\"\n",
        "            latency_label.value = f\"Saccadic Latency: {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"Smooth Pursuit Gain: {smooth_pursuit_gain:.2f}\"\n",
        "            search_time_label.value = f\"Search Time: {total_search_time:.2f} ms\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "xd7wAvyqNN6f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}