{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "OgE6dNoHxfpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices\n",
        "LEFT_EYE_INDICES = [33, 133, 160, 159, 158, 157, 173, 153, 144, 145, 153]\n",
        "RIGHT_EYE_INDICES = [362, 263, 387, 386, 385, 384, 398, 382, 381, 380, 374]\n",
        "\n",
        "# Initialize variables for tracking\n",
        "previous_center = None\n",
        "speed = 0\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to calculate the center of the eye\n",
        "def calculate_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "# Function to display video frames in Colab\n",
        "def display_frame(image):\n",
        "    # Convert BGR to RGB\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # Convert to PIL Image\n",
        "    pil_img = Image.fromarray(image_rgb)\n",
        "    # Display the image\n",
        "    display(pil_img)\n",
        "\n",
        "# Callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    # Decode the Base64 image\n",
        "    header, encoded = dataURL.split(\",\", 1)\n",
        "    data = b64decode(encoded)\n",
        "    img = Image.open(io.BytesIO(data))\n",
        "    img = img.convert('RGB')\n",
        "    img = np.array(img)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    with lock:\n",
        "        frames.append(img)\n",
        "\n",
        "# Register the callback\n",
        "from google.colab import output\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 100);  // Send frame every 100ms\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Function to process frames and display results\n",
        "def process_frames():\n",
        "    global previous_center, speed\n",
        "    while True:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center\n",
        "                    cv2.circle(frame, eye_center, 5, (0, 255, 255), -1)\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        speed = math.sqrt(dx**2 + dy**2)\n",
        "                    previous_center = eye_center\n",
        "\n",
        "                    # Display speed on the frame\n",
        "                    cv2.putText(frame, f'Speed: {speed:.2f}', (10, 30),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "            # Display the processed frame\n",
        "            display_frame(frame)\n",
        "            # Clear previous output\n",
        "            from IPython.display import clear_output\n",
        "            clear_output(wait=True)\n",
        "        time.sleep(0.1)  # Adjust the sleep time as needed\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "thread = threading.Thread(target=process_frames)\n",
        "thread.start()\n",
        "\n",
        "# To stop the processing, interrupt the kernel (e.g., by clicking the stop button)\n"
      ],
      "metadata": {
        "id": "s3TTl5C3wQS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "First"
      ],
      "metadata": {
        "id": "AXyF4Rm8xjvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices\n",
        "LEFT_EYE_INDICES = [33, 133, 160, 159, 158, 157, 173, 153, 144, 145, 153]\n",
        "RIGHT_EYE_INDICES = [362, 263, 387, 386, 385, 384, 398, 382, 381, 380, 374]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([hbox, speed_label])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position\n",
        "    amplification_factor = 20  # Increased amplification for clearer movement\n",
        "    while True:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.zeros((224, 224, 3), dtype=np.uint8)  # Black background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Update yellow_dot_position based on movement delta\n",
        "                    yellow_dot_position[0] += int(dx * amplification_factor)\n",
        "                    yellow_dot_position[1] += int(dy * amplification_factor)\n",
        "\n",
        "                    # Clip the yellow_dot_position within the frame\n",
        "                    yellow_dot_position[0] = max(0, min(223, yellow_dot_position[0]))\n",
        "                    yellow_dot_position[1] = max(0, min(223, yellow_dot_position[1]))\n",
        "\n",
        "                    # Draw the yellow dot on the separate frame\n",
        "                    cv2.circle(yellow_dot_frame, (yellow_dot_position[0], yellow_dot_position[1]), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update speed info\n",
        "            speed_label.value = speed_info\n",
        "\n",
        "        # Control frame rate (currently 20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Note:\n",
        "# To stop the processing, interrupt the Colab kernel by clicking the \"Stop\" button.\n"
      ],
      "metadata": {
        "id": "cyPwkbUtH_o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second"
      ],
      "metadata": {
        "id": "J6h12QjTg7Jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "blink_label = widgets.Label(value=\"Blink Count: 0\")                     # Blink count\n",
        "fixation_label = widgets.Label(value=\"Fixation Duration: 0.00 sec\")    # Fixation duration\n",
        "pupil_label = widgets.Label(value=\"Pupil Diameter: 0.00 mm\")            # Pupil diameter\n",
        "gaze_label = widgets.Label(value=\"Gaze Deviation: 0.00 degrees\")       # Gaze deviation\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([hbox, speed_label, blink_label, fixation_label, pupil_label, gaze_label])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag, fixation_start_time, fixation_duration, data_records\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "    while True:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels\n",
        "            speed_label.value = speed_info\n",
        "            blink_label.value = f\"Blink Count: {blink_count}\"\n",
        "            fixation_label.value = fixation_info\n",
        "            pupil_label.value = f\"Pupil Diameter: {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"Gaze Deviation: {gaze_deviation:.2f} degrees\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the kernel is interrupted\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "4qHzrfWWg2XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third"
      ],
      "metadata": {
        "id": "KZ0ff1EbJ7F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "blink_label = widgets.Label(value=\"Blink Count: 0\")                     # Blink count\n",
        "fixation_label = widgets.Label(value=\"Fixation Duration: 0.00 sec\")    # Fixation duration\n",
        "pupil_label = widgets.Label(value=\"Pupil Diameter: 0.00 mm\")            # Pupil diameter\n",
        "gaze_label = widgets.Label(value=\"Gaze Deviation: 0.00 degrees\")       # Gaze deviation\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\", button_style='danger')\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([hbox, speed_label, blink_label, fixation_label, pupil_label, gaze_label, stop_button])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag, fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels\n",
        "            speed_label.value = speed_info\n",
        "            blink_label.value = f\"Blink Count: {blink_count}\"\n",
        "            fixation_label.value = fixation_info\n",
        "            pupil_label.value = f\"Pupil Diameter: {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"Gaze Deviation: {gaze_deviation:.2f} degrees\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "ujixL8GEJ9Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forth"
      ],
      "metadata": {
        "id": "09kGlF6JNMi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "saccade_start_time = None\n",
        "saccadic_latency = 0\n",
        "smooth_pursuit_gain = 0\n",
        "search_time_start = None\n",
        "total_search_time = 0\n",
        "target_search_count = 0\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "def calculate_smooth_pursuit_gain(eye_center, previous_center, width, height):\n",
        "    if previous_center is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate movement distance\n",
        "    eye_movement = math.sqrt((eye_center[0] - previous_center[0])**2 + (eye_center[1] - previous_center[1])**2)\n",
        "    # Approximate target velocity using movement (can be improved with actual target data)\n",
        "    target_movement = math.sqrt(width**2 + height**2) / 60  # Assuming a screen-sized target moving at 60Hz\n",
        "    return eye_movement / target_movement\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "blink_label = widgets.Label(value=\"Blink Count: 0\")                     # Blink count\n",
        "fixation_label = widgets.Label(value=\"Fixation Duration: 0.00 sec\")    # Fixation duration\n",
        "pupil_label = widgets.Label(value=\"Pupil Diameter: 0.00 mm\")            # Pupil diameter\n",
        "gaze_label = widgets.Label(value=\"Gaze Deviation: 0.00 degrees\")       # Gaze deviation\n",
        "latency_label = widgets.Label(value=\"Saccadic Latency: 0 ms\")           # Saccadic latency\n",
        "smooth_pursuit_label = widgets.Label(value=\"Smooth Pursuit Gain: 0.00\") # Smooth pursuit gain\n",
        "search_time_label = widgets.Label(value=\"Search Time: 0 ms\")            # Search time\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\", button_style='danger')\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([hbox, speed_label, blink_label, fixation_label, pupil_label, gaze_label, latency_label, smooth_pursuit_label, search_time_label, stop_button])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag, fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global saccade_start_time, saccadic_latency, smooth_pursuit_gain, search_time_start, total_search_time, target_search_count\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Search Time in Serial Search\n",
        "                    if search_time_start is None:\n",
        "                        search_time_start = current_time\n",
        "                    else:\n",
        "                        total_search_time = (current_time - search_time_start) * 1000  # in ms\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Search_Time_ms\": total_search_time\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels\n",
        "            speed_label.value = speed_info\n",
        "            blink_label.value = f\"Blink Count: {blink_count}\"\n",
        "            fixation_label.value = fixation_info\n",
        "            pupil_label.value = f\"Pupil Diameter: {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"Gaze Deviation: {gaze_deviation:.2f} degrees\"\n",
        "            latency_label.value = f\"Saccadic Latency: {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"Smooth Pursuit Gain: {smooth_pursuit_gain:.2f}\"\n",
        "            search_time_label.value = f\"Search Time: {total_search_time:.2f} ms\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "xd7wAvyqNN6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "9ZLP8HfdOpMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "BMALzdOYOpts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fifth"
      ],
      "metadata": {
        "id": "aJNfjKTrpLGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas scipy\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
        "import numpy.linalg as la\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "saccade_start_time = None\n",
        "saccadic_latency = 0\n",
        "smooth_pursuit_gain = 0\n",
        "search_time_start = None\n",
        "total_search_time = 0\n",
        "target_search_count = 0\n",
        "\n",
        "# Initialize variables for new features\n",
        "head_pose = {\"yaw\": 0, \"pitch\": 0, \"roll\": 0}\n",
        "fixation_points = []\n",
        "microsaccades = 0\n",
        "eye_openness_left = 0.0\n",
        "eye_openness_right = 0.0\n",
        "previous_fixation_point = None\n",
        "pupil_shape_deformation = 0.0\n",
        "\n",
        "# Define helper functions\n",
        "\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "def calculate_smooth_pursuit_gain(eye_center, previous_center, width, height):\n",
        "    if previous_center is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate movement distance\n",
        "    eye_movement = math.sqrt((eye_center[0] - previous_center[0])**2 + (eye_center[1] - previous_center[1])**2)\n",
        "    # Approximate target velocity using movement (can be improved with actual target data)\n",
        "    target_movement = math.sqrt(width**2 + height**2) / 60  # Assuming a screen-sized target moving at 60Hz\n",
        "    return eye_movement / target_movement\n",
        "\n",
        "# New Feature Functions\n",
        "\n",
        "def calculate_pcr_ratio(landmarks, width, height):\n",
        "    eye_top = landmarks[1]  # Assuming landmark 1 is the top reflection point\n",
        "    eye_bottom = landmarks[5]  # Assuming landmark 5 is the bottom reflection point\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    # Compute the PCR ratio\n",
        "    return vertical_distance / height  # Normalize by the frame height\n",
        "\n",
        "def calculate_3d_gaze_direction(landmarks):\n",
        "    eye_vector = np.array([landmarks[1].x - landmarks[5].x, landmarks[1].y - landmarks[5].y])\n",
        "    gaze_angle = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    return gaze_angle\n",
        "\n",
        "def calculate_eye_openness(landmarks, indices, width, height):\n",
        "    eye_top = landmarks[indices[1]]\n",
        "    eye_bottom = landmarks[indices[5]]\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    return vertical_distance\n",
        "\n",
        "def calculate_pupil_shape_deformation(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]\n",
        "    if len(iris_landmarks) < 4:\n",
        "        return 0.0\n",
        "    distances = [\n",
        "        math.dist(\n",
        "            (iris_landmarks[i].x * width, iris_landmarks[i].y * height),\n",
        "            (iris_landmarks[j].x * width, iris_landmarks[j].y * height)\n",
        "        )\n",
        "        for i in range(len(iris_landmarks))\n",
        "        for j in range(i+1, len(iris_landmarks))\n",
        "    ]\n",
        "    max_dist = max(distances)\n",
        "    min_dist = min(distances)\n",
        "    return max_dist / min_dist if min_dist > 0 else 0.0\n",
        "\n",
        "def estimate_head_pose(landmarks, width, height):\n",
        "    # Use specific landmarks to approximate head orientation\n",
        "    nose_tip = landmarks[1]  # Assuming 1 is the nose tip\n",
        "    left_eye = landmarks[33]  # Assuming 33 is the left eye corner\n",
        "    right_eye = landmarks[263]  # Assuming 263 is the right eye corner\n",
        "\n",
        "    eye_vector = np.array([left_eye.x - right_eye.x, left_eye.y - right_eye.y])\n",
        "    yaw = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    pitch = np.degrees(np.arctan2(\n",
        "        nose_tip.y - (left_eye.y + right_eye.y) / 2,\n",
        "        nose_tip.x - (left_eye.x + right_eye.x) / 2\n",
        "    ))\n",
        "\n",
        "    return {\"yaw\": yaw, \"pitch\": pitch, \"roll\": 0}  # Simplified roll estimation\n",
        "\n",
        "def detect_microsaccades(eye_center, previous_center):\n",
        "    if previous_center is None:\n",
        "        return 0\n",
        "    movement = math.sqrt(\n",
        "        (eye_center[0] - previous_center[0]) ** 2 +\n",
        "        (eye_center[1] - previous_center[1]) ** 2\n",
        "    )\n",
        "    if 0.1 < movement < 1.0:  # Threshold range for microsaccades\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# Process frames with additional features\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag\n",
        "    global fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global microsaccades, head_pose, eye_openness_left, eye_openness_right\n",
        "    global pupil_shape_deformation, previous_fixation_point\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Search Time in Serial Search\n",
        "                    if search_time_start is None:\n",
        "                        search_time_start = current_time\n",
        "                    else:\n",
        "                        total_search_time = (current_time - search_time_start) * 1000  # in ms\n",
        "\n",
        "                    # New Features Calculations\n",
        "                    microsaccades += detect_microsaccades(eye_center, previous_center)\n",
        "                    head_pose = estimate_head_pose(face_landmarks.landmark, width, height)\n",
        "                    eye_openness_left = calculate_eye_openness(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    eye_openness_right = calculate_eye_openness(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "                    pupil_shape_deformation = calculate_pupil_shape_deformation(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "                    pcr_ratio = calculate_pcr_ratio(face_landmarks.landmark, width, height)\n",
        "                    gaze_direction = calculate_3d_gaze_direction(face_landmarks.landmark)\n",
        "\n",
        "                    # Update fixation points and fixation duration\n",
        "                    if fixation_start_time is None:\n",
        "                        fixation_start_time = current_time\n",
        "                    elif math.sqrt(dx ** 2 + dy ** 2) < fixation_threshold:\n",
        "                        fixation_points.append(eye_center)\n",
        "                        fixation_duration = current_time - fixation_start_time\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"PCR_Ratio\": pcr_ratio,\n",
        "                        \"3D_Gaze_Direction_deg\": gaze_direction,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Head_Pose_Yaw\": head_pose[\"yaw\"],\n",
        "                        \"Head_Pose_Pitch\": head_pose[\"pitch\"],\n",
        "                        \"Eye_Openness_Left\": eye_openness_left,\n",
        "                        \"Eye_Openness_Right\": eye_openness_right,\n",
        "                        \"Pupil_Shape_Deformation\": pupil_shape_deformation,\n",
        "                        \"Microsaccades\": microsaccades\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels for new features\n",
        "            blink_label.value = f\"Blink Count: {blink_count}\"\n",
        "            fixation_label.value = fixation_info\n",
        "            latency_label.value = f\"Saccadic Latency: {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"Smooth Pursuit Gain: {smooth_pursuit_gain:.2f}\"\n",
        "            gaze_label.value = f\"Gaze Direction: {gaze_direction:.2f} degrees\"\n",
        "            search_time_label.value = f\"Microsaccades: {microsaccades}\"\n",
        "            # Additional labels for new features\n",
        "            head_pose_label.value = f\"Head Pose - Yaw: {head_pose['yaw']:.2f}, Pitch: {head_pose['pitch']:.2f}, Roll: {head_pose['roll']:.2f}\"\n",
        "            eye_openness_label.value = f\"Eye Openness - Left: {eye_openness_left:.2f}, Right: {eye_openness_right:.2f}\"\n",
        "            pupil_deformation_label.value = f\"Pupil Shape Deformation: {pupil_shape_deformation:.2f}\"\n",
        "            pcr_ratio_label.value = f\"PCR Ratio: {pcr_ratio:.2f}\"\n",
        "            gaze_direction_label.value = f\"3D Gaze Direction: {gaze_direction:.2f} degrees\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# The rest of your streaming and control code remains unchanged\n",
        "# Define additional labels for new features\n",
        "head_pose_label = widgets.Label(value=\"Head Pose - Yaw: 0.00, Pitch: 0.00, Roll: 0.00\")\n",
        "eye_openness_label = widgets.Label(value=\"Eye Openness - Left: 0.00, Right: 0.00\")\n",
        "pupil_deformation_label = widgets.Label(value=\"Pupil Shape Deformation: 0.00\")\n",
        "pcr_ratio_label = widgets.Label(value=\"PCR Ratio: 0.00\")\n",
        "gaze_direction_label = widgets.Label(value=\"3D Gaze Direction: 0.00 degrees\")\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "speed_label = widgets.Label(value=\"Saccade Speed: 0.00 pixels/sec (N/A)\") # Speed and classification info\n",
        "blink_label = widgets.Label(value=\"Blink Count: 0\")                     # Blink count\n",
        "fixation_label = widgets.Label(value=\"Fixation Duration: 0.00 sec\")    # Fixation duration\n",
        "pupil_label = widgets.Label(value=\"Pupil Diameter: 0.00 mm\")            # Pupil diameter\n",
        "gaze_label = widgets.Label(value=\"Gaze Deviation: 0.00 degrees\")       # Gaze deviation\n",
        "latency_label = widgets.Label(value=\"Saccadic Latency: 0 ms\")           # Saccadic latency\n",
        "smooth_pursuit_label = widgets.Label(value=\"Smooth Pursuit Gain: 0.00\") # Smooth pursuit gain\n",
        "search_time_label = widgets.Label(value=\"Search Time: 0 ms\")            # Search time\n",
        "\n",
        "# Additional Labels for New Features\n",
        "head_pose_label = widgets.Label(value=\"Head Pose - Yaw: 0.00, Pitch: 0.00, Roll: 0.00\")\n",
        "eye_openness_label = widgets.Label(value=\"Eye Openness - Left: 0.00, Right: 0.00\")\n",
        "pupil_deformation_label = widgets.Label(value=\"Pupil Shape Deformation: 0.00\")\n",
        "pcr_ratio_label = widgets.Label(value=\"PCR Ratio: 0.00\")\n",
        "gaze_direction_label = widgets.Label(value=\"3D Gaze Direction: 0.00 degrees\")\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\", button_style='danger')\n",
        "\n",
        "# Arrange the widgets in the notebook\n",
        "hbox = widgets.HBox([face_image, yellow_dot_image])\n",
        "vbox = widgets.VBox([\n",
        "    hbox,\n",
        "    speed_label,\n",
        "    blink_label,\n",
        "    fixation_label,\n",
        "    pupil_label,\n",
        "    gaze_label,\n",
        "    latency_label,\n",
        "    smooth_pursuit_label,\n",
        "    search_time_label,\n",
        "    head_pose_label,\n",
        "    eye_openness_label,\n",
        "    pupil_deformation_label,\n",
        "    pcr_ratio_label,\n",
        "    gaze_direction_label,\n",
        "    stop_button\n",
        "])\n",
        "display(vbox)\n",
        "\n",
        "# Define the function to process and display frames\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag\n",
        "    global fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global microsaccades  # Declare microsaccades as global\n",
        "    global head_pose, eye_openness_left, eye_openness_right\n",
        "    global pupil_shape_deformation, previous_fixation_point\n",
        "    global saccade_start_time, saccadic_latency, smooth_pursuit_gain, search_time_start\n",
        "    global total_search_time, target_search_count\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Search Time in Serial Search\n",
        "                    if search_time_start is None:\n",
        "                        search_time_start = current_time\n",
        "                    else:\n",
        "                        total_search_time = (current_time - search_time_start) * 1000  # in ms\n",
        "\n",
        "                    # New Features Calculations\n",
        "                    microsaccades += detect_microsaccades(eye_center, previous_center)\n",
        "                    head_pose = estimate_head_pose(face_landmarks.landmark, width, height)\n",
        "                    eye_openness_left = calculate_eye_openness(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    eye_openness_right = calculate_eye_openness(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "                    pupil_shape_deformation = calculate_pupil_shape_deformation(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "                    pcr_ratio = calculate_pcr_ratio(face_landmarks.landmark, width, height)\n",
        "                    gaze_direction = calculate_3d_gaze_direction(face_landmarks.landmark)\n",
        "\n",
        "                    # Update fixation points and fixation duration\n",
        "                    if fixation_start_time is None:\n",
        "                        fixation_start_time = current_time\n",
        "                    elif math.sqrt(dx ** 2 + dy ** 2) < fixation_threshold:\n",
        "                        fixation_points.append(eye_center)\n",
        "                        fixation_duration = current_time - fixation_start_time\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"PCR_Ratio\": pcr_ratio,\n",
        "                        \"3D_Gaze_Direction_deg\": gaze_direction,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Head_Pose_Yaw\": head_pose[\"yaw\"],\n",
        "                        \"Head_Pose_Pitch\": head_pose[\"pitch\"],\n",
        "                        \"Eye_Openness_Left\": eye_openness_left,\n",
        "                        \"Eye_Openness_Right\": eye_openness_right,\n",
        "                        \"Pupil_Shape_Deformation\": pupil_shape_deformation,\n",
        "                        \"Microsaccades\": microsaccades\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels for new features\n",
        "            speed_label.value = speed_info\n",
        "            blink_label.value = f\"Blink Count: {blink_count}\"\n",
        "            fixation_label.value = fixation_info\n",
        "            pupil_label.value = f\"Pupil Diameter: {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"Gaze Deviation: {gaze_deviation:.2f} degrees\"\n",
        "            latency_label.value = f\"Saccadic Latency: {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"Smooth Pursuit Gain: {smooth_pursuit_gain:.2f}\"\n",
        "            search_time_label.value = f\"Microsaccades: {microsaccades}\"\n",
        "            # Update additional labels\n",
        "            head_pose_label.value = f\"Head Pose - Yaw: {head_pose['yaw']:.2f}, Pitch: {head_pose['pitch']:.2f}, Roll: {head_pose['roll']:.2f}\"\n",
        "            eye_openness_label.value = f\"Eye Openness - Left: {eye_openness_left:.2f}, Right: {eye_openness_right:.2f}\"\n",
        "            pupil_deformation_label.value = f\"Pupil Shape Deformation: {pupil_shape_deformation:.2f}\"\n",
        "            pcr_ratio_label.value = f\"PCR Ratio: {pcr_ratio:.2f}\"\n",
        "            gaze_direction_label.value = f\"3D Gaze Direction: {gaze_direction:.2f} degrees\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "EOKNnjbDv7kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas scipy\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
        "import numpy.linalg as la\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "saccade_start_time = None\n",
        "saccadic_latency = 0\n",
        "smooth_pursuit_gain = 0\n",
        "search_time_start = None\n",
        "total_search_time = 0\n",
        "target_search_count = 0\n",
        "\n",
        "# Initialize variables for new features\n",
        "head_pose = {\"yaw\": 0, \"pitch\": 0, \"roll\": 0}\n",
        "fixation_points = []\n",
        "microsaccades = 0\n",
        "eye_openness_left = 0.0\n",
        "eye_openness_right = 0.0\n",
        "previous_fixation_point = None\n",
        "pupil_shape_deformation = 0.0\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "def calculate_smooth_pursuit_gain(eye_center, previous_center, width, height):\n",
        "    if previous_center is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate movement distance\n",
        "    eye_movement = math.sqrt((eye_center[0] - previous_center[0])**2 + (eye_center[1] - previous_center[1])**2)\n",
        "    # Approximate target velocity using movement (can be improved with actual target data)\n",
        "    target_movement = math.sqrt(width**2 + height**2) / 60  # Assuming a screen-sized target moving at 60Hz\n",
        "    return eye_movement / target_movement\n",
        "\n",
        "# New Feature Functions\n",
        "def calculate_pcr_ratio(landmarks, width, height):\n",
        "    eye_top = landmarks[1]  # Assuming landmark 1 is the top reflection point\n",
        "    eye_bottom = landmarks[5]  # Assuming landmark 5 is the bottom reflection point\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    # Compute the PCR ratio\n",
        "    return vertical_distance / height  # Normalize by the frame height\n",
        "\n",
        "def calculate_3d_gaze_direction(landmarks):\n",
        "    eye_vector = np.array([landmarks[1].x - landmarks[5].x, landmarks[1].y - landmarks[5].y])\n",
        "    gaze_angle = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    return gaze_angle\n",
        "\n",
        "def calculate_eye_openness(landmarks, indices, width, height):\n",
        "    eye_top = landmarks[indices[1]]\n",
        "    eye_bottom = landmarks[indices[5]]\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    return vertical_distance\n",
        "\n",
        "def calculate_pupil_shape_deformation(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]\n",
        "    if len(iris_landmarks) < 4:\n",
        "        return 0.0\n",
        "    distances = [\n",
        "        math.dist(\n",
        "            (iris_landmarks[i].x * width, iris_landmarks[i].y * height),\n",
        "            (iris_landmarks[j].x * width, iris_landmarks[j].y * height)\n",
        "        )\n",
        "        for i in range(len(iris_landmarks))\n",
        "        for j in range(i+1, len(iris_landmarks))\n",
        "    ]\n",
        "    max_dist = max(distances)\n",
        "    min_dist = min(distances)\n",
        "    return max_dist / min_dist if min_dist > 0 else 0.0\n",
        "\n",
        "def estimate_head_pose(landmarks, width, height):\n",
        "    # Use specific landmarks to approximate head orientation\n",
        "    nose_tip = landmarks[1]  # Assuming 1 is the nose tip\n",
        "    left_eye = landmarks[33]  # Assuming 33 is the left eye corner\n",
        "    right_eye = landmarks[263]  # Assuming 263 is the right eye corner\n",
        "\n",
        "    eye_vector = np.array([left_eye.x - right_eye.x, left_eye.y - right_eye.y])\n",
        "    yaw = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    pitch = np.degrees(np.arctan2(\n",
        "        nose_tip.y - (left_eye.y + right_eye.y) / 2,\n",
        "        nose_tip.x - (left_eye.x + right_eye.x) / 2\n",
        "    ))\n",
        "\n",
        "    return {\"yaw\": yaw, \"pitch\": pitch, \"roll\": 0}  # Simplified roll estimation\n",
        "\n",
        "def detect_microsaccades(eye_center, previous_center):\n",
        "    if previous_center is None:\n",
        "        return 0\n",
        "    movement = math.sqrt(\n",
        "        (eye_center[0] - previous_center[0]) ** 2 +\n",
        "        (eye_center[1] - previous_center[1]) ** 2\n",
        "    )\n",
        "    if 0.1 < movement < 1.0:  # Threshold range for microsaccades\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "\n",
        "# Create labels with enhanced styling\n",
        "speed_label = widgets.HTML(value=\"<b>Saccade Speed:</b> 0.00 pixels/sec (N/A)\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "blink_label = widgets.HTML(value=\"<b>Blinks:</b> 0\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "fixation_label = widgets.HTML(value=\"<b>Fixation Duration:</b> 0.00 sec\",\n",
        "                              layout=widgets.Layout(margin='5px 0px'))\n",
        "pupil_label = widgets.HTML(value=\"<b>Pupil Diameter:</b> 0.00 mm\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "gaze_label = widgets.HTML(value=\"<b>Gaze Deviation:</b> 0.00°\",\n",
        "                          layout=widgets.Layout(margin='5px 0px'))\n",
        "latency_label = widgets.HTML(value=\"<b>Saccadic Latency:</b> 0.00 ms\",\n",
        "                             layout=widgets.Layout(margin='5px 0px'))\n",
        "smooth_pursuit_label = widgets.HTML(value=\"<b>Smooth Pursuit Gain:</b> 0.00\",\n",
        "                                    layout=widgets.Layout(margin='5px 0px'))\n",
        "search_time_label = widgets.HTML(value=\"<b>Microsaccades:</b> 0\",\n",
        "                                 layout=widgets.Layout(margin='5px 0px'))\n",
        "\n",
        "# Additional Labels for New Features with enhanced styling\n",
        "head_pose_label = widgets.HTML(value=\"<b>Head Pose:</b> Yaw: 0.00°, Pitch: 0.00°, Roll: 0.00°\",\n",
        "                               layout=widgets.Layout(margin='5px 0px'))\n",
        "eye_openness_label = widgets.HTML(value=\"<b>Eye Openness:</b> Left: 0.00, Right: 0.00\",\n",
        "                                   layout=widgets.Layout(margin='5px 0px'))\n",
        "pcr_ratio_label = widgets.HTML(value=\"<b>PCR Ratio:</b> 0.00\",\n",
        "                                layout=widgets.Layout(margin='5px 0px'))\n",
        "pupil_deformation_label = widgets.HTML(value=\"<b>Pupil Shape Deformation:</b> 0.00\",\n",
        "                                       layout=widgets.Layout(margin='5px 0px'))\n",
        "gaze_direction_label = widgets.HTML(value=\"<b>3D Gaze Direction:</b> 0.00°\",\n",
        "                                     layout=widgets.Layout(margin='5px 0px'))\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\",\n",
        "                             button_style='danger',\n",
        "                             tooltip='Click to stop the video stream and save data',\n",
        "                             layout=widgets.Layout(width='150px', height='40px'))\n",
        "\n",
        "# Organize metrics into sections\n",
        "metrics_tab = widgets.Tab()\n",
        "metrics_tab.children = [\n",
        "    widgets.VBox([\n",
        "        speed_label,\n",
        "        blink_label,\n",
        "        fixation_label,\n",
        "        pupil_label,\n",
        "        gaze_label,\n",
        "        latency_label,\n",
        "        smooth_pursuit_label,\n",
        "        search_time_label\n",
        "    ], layout=widgets.Layout(padding='10px')),\n",
        "    widgets.VBox([\n",
        "        head_pose_label,\n",
        "        eye_openness_label,\n",
        "        pcr_ratio_label,\n",
        "        pupil_deformation_label,\n",
        "        gaze_direction_label\n",
        "    ], layout=widgets.Layout(padding='10px'))\n",
        "]\n",
        "\n",
        "# Set tab titles\n",
        "metrics_tab.set_title(0, 'Performance Metrics')\n",
        "metrics_tab.set_title(1, 'Additional Features')\n",
        "\n",
        "# Arrange the widgets in the notebook using Grids for better layout\n",
        "images_box = widgets.HBox([face_image, yellow_dot_image], layout=widgets.Layout(justify_content='space-between', width='100%'))\n",
        "\n",
        "controls_box = widgets.VBox([\n",
        "    metrics_tab,\n",
        "    stop_button\n",
        "], layout=widgets.Layout(padding='10px'))\n",
        "\n",
        "# Combine all into a main VBox\n",
        "main_box = widgets.VBox([\n",
        "    widgets.HTML(value=\"<h2 style='text-align: center;'>Eye Movement Tracking Dashboard</h2>\"),\n",
        "    images_box,\n",
        "    controls_box\n",
        "], layout=widgets.Layout(align_items='center', padding='20px'))\n",
        "\n",
        "display(main_box)\n",
        "\n",
        "# Process frames with additional features\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag\n",
        "    global fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global microsaccades, head_pose, eye_openness_left, eye_openness_right\n",
        "    global pupil_shape_deformation, previous_fixation_point\n",
        "    global saccade_start_time, saccadic_latency, smooth_pursuit_gain, search_time_start\n",
        "    global total_search_time, target_search_count\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Search Time in Serial Search\n",
        "                    if search_time_start is None:\n",
        "                        search_time_start = current_time\n",
        "                    else:\n",
        "                        total_search_time = (current_time - search_time_start) * 1000  # in ms\n",
        "\n",
        "                    # New Features Calculations\n",
        "                    microsaccades += detect_microsaccades(eye_center, previous_center)\n",
        "                    head_pose = estimate_head_pose(face_landmarks.landmark, width, height)\n",
        "                    eye_openness_left = calculate_eye_openness(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    eye_openness_right = calculate_eye_openness(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "                    pupil_shape_deformation = calculate_pupil_shape_deformation(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "                    pcr_ratio = calculate_pcr_ratio(face_landmarks.landmark, width, height)\n",
        "                    gaze_direction = calculate_3d_gaze_direction(face_landmarks.landmark)\n",
        "\n",
        "                    # Update fixation points and fixation duration\n",
        "                    if fixation_start_time is None:\n",
        "                        fixation_start_time = current_time\n",
        "                    elif math.sqrt(dx ** 2 + dy ** 2) < fixation_threshold:\n",
        "                        fixation_points.append(eye_center)\n",
        "                        fixation_duration = current_time - fixation_start_time\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"PCR_Ratio\": pcr_ratio,\n",
        "                        \"3D_Gaze_Direction_deg\": gaze_direction,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Head_Pose_Yaw\": head_pose[\"yaw\"],\n",
        "                        \"Head_Pose_Pitch\": head_pose[\"pitch\"],\n",
        "                        \"Eye_Openness_Left\": eye_openness_left,\n",
        "                        \"Eye_Openness_Right\": eye_openness_right,\n",
        "                        \"Pupil_Shape_Deformation\": pupil_shape_deformation,\n",
        "                        \"Microsaccades\": microsaccades\n",
        "                    })\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels for new features\n",
        "            speed_label.value = f\"<b>Saccade Speed:</b> {speed:.2f} pixels/sec ({speed_class})\"\n",
        "            blink_label.value = f\"<b>Blinks:</b> {blink_count}\"\n",
        "            fixation_label.value = f\"<b>Fixation Duration:</b> {fixation_duration:.2f} sec\"\n",
        "            pupil_label.value = f\"<b>Pupil Diameter:</b> {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"<b>Gaze Deviation:</b> {gaze_deviation:.2f}°\"\n",
        "            latency_label.value = f\"<b>Saccadic Latency:</b> {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"<b>Smooth Pursuit Gain:</b> {smooth_pursuit_gain:.2f}\"\n",
        "            search_time_label.value = f\"<b>Microsaccades:</b> {microsaccades}\"\n",
        "            head_pose_label.value = f\"<b>Head Pose:</b> Yaw: {head_pose['yaw']:.2f}°, Pitch: {head_pose['pitch']:.2f}°, Roll: {head_pose['roll']:.2f}°\"\n",
        "            eye_openness_label.value = f\"<b>Eye Openness:</b> Left: {eye_openness_left:.2f}, Right: {eye_openness_right:.2f}\"\n",
        "            pcr_ratio_label.value = f\"<b>PCR Ratio:</b> {pcr_ratio:.2f}\"\n",
        "            pupil_deformation_label.value = f\"<b>Pupil Shape Deformation:</b> {pupil_shape_deformation:.2f}\"\n",
        "            gaze_direction_label.value = f\"<b>3D Gaze Direction:</b> {gaze_direction:.2f}°\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "RAHZybhmsRqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas scipy plotly\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
        "import numpy.linalg as la\n",
        "\n",
        "# Enable custom widget manager for Plotly in Colab\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "saccade_start_time = None\n",
        "saccadic_latency = 0\n",
        "smooth_pursuit_gain = 0\n",
        "search_time_start = None\n",
        "total_search_time = 0\n",
        "target_search_count = 0\n",
        "\n",
        "# Initialize variables for new features\n",
        "head_pose = {\"yaw\": 0, \"pitch\": 0, \"roll\": 0}\n",
        "fixation_points = []\n",
        "microsaccades = 0\n",
        "eye_openness_left = 0.0\n",
        "eye_openness_right = 0.0\n",
        "previous_fixation_point = None\n",
        "pupil_shape_deformation = 0.0\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "def calculate_smooth_pursuit_gain(eye_center, previous_center, width, height):\n",
        "    if previous_center is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate movement distance\n",
        "    eye_movement = math.sqrt((eye_center[0] - previous_center[0])**2 + (eye_center[1] - previous_center[1])**2)\n",
        "    # Approximate target velocity using movement (can be improved with actual target data)\n",
        "    target_movement = math.sqrt(width**2 + height**2) / 60  # Assuming a screen-sized target moving at 60Hz\n",
        "    return eye_movement / target_movement\n",
        "\n",
        "# New Feature Functions\n",
        "def calculate_pcr_ratio(landmarks, width, height):\n",
        "    eye_top = landmarks[1]  # Assuming landmark 1 is the top reflection point\n",
        "    eye_bottom = landmarks[5]  # Assuming landmark 5 is the bottom reflection point\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    # Compute the PCR ratio\n",
        "    return vertical_distance / height  # Normalize by the frame height\n",
        "\n",
        "def calculate_3d_gaze_direction(landmarks):\n",
        "    eye_vector = np.array([landmarks[1].x - landmarks[5].x, landmarks[1].y - landmarks[5].y])\n",
        "    gaze_angle = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    return gaze_angle\n",
        "\n",
        "def calculate_eye_openness(landmarks, indices, width, height):\n",
        "    eye_top = landmarks[indices[1]]\n",
        "    eye_bottom = landmarks[indices[5]]\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    return vertical_distance\n",
        "\n",
        "def calculate_pupil_shape_deformation(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]\n",
        "    if len(iris_landmarks) < 4:\n",
        "        return 0.0\n",
        "    distances = [\n",
        "        math.dist(\n",
        "            (iris_landmarks[i].x * width, iris_landmarks[i].y * height),\n",
        "            (iris_landmarks[j].x * width, iris_landmarks[j].y * height)\n",
        "        )\n",
        "        for i in range(len(iris_landmarks))\n",
        "        for j in range(i+1, len(iris_landmarks))\n",
        "    ]\n",
        "    max_dist = max(distances)\n",
        "    min_dist = min(distances)\n",
        "    return max_dist / min_dist if min_dist > 0 else 0.0\n",
        "\n",
        "def estimate_head_pose(landmarks, width, height):\n",
        "    # Use specific landmarks to approximate head orientation\n",
        "    nose_tip = landmarks[1]  # Assuming 1 is the nose tip\n",
        "    left_eye = landmarks[33]  # Assuming 33 is the left eye corner\n",
        "    right_eye = landmarks[263]  # Assuming 263 is the right eye corner\n",
        "\n",
        "    eye_vector = np.array([left_eye.x - right_eye.x, left_eye.y - right_eye.y])\n",
        "    yaw = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    pitch = np.degrees(np.arctan2(\n",
        "        nose_tip.y - (left_eye.y + right_eye.y) / 2,\n",
        "        nose_tip.x - (left_eye.x + right_eye.x) / 2\n",
        "    ))\n",
        "\n",
        "    return {\"yaw\": yaw, \"pitch\": pitch, \"roll\": 0}  # Simplified roll estimation\n",
        "\n",
        "def detect_microsaccades(eye_center, previous_center):\n",
        "    if previous_center is None:\n",
        "        return 0\n",
        "    movement = math.sqrt(\n",
        "        (eye_center[0] - previous_center[0]) ** 2 +\n",
        "        (eye_center[1] - previous_center[1]) ** 2\n",
        "    )\n",
        "    if 0.1 < movement < 1.0:  # Threshold range for microsaccades\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "\n",
        "# Create Plotly real-time graphs\n",
        "saccade_speed_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='blue'))],\n",
        "    layout=go.Layout(\n",
        "        title=\"Saccade Speed Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Speed (pixels/sec)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "blink_count_fig = go.FigureWidget(\n",
        "    data=[go.Bar(x=[], y=[], marker_color='orange')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Blink Count Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Blinks\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create labels with enhanced styling\n",
        "speed_label = widgets.HTML(value=\"<b>Saccade Speed:</b> 0.00 pixels/sec (N/A)\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "blink_label = widgets.HTML(value=\"<b>Blinks:</b> 0\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "fixation_label = widgets.HTML(value=\"<b>Fixation Duration:</b> 0.00 sec\",\n",
        "                              layout=widgets.Layout(margin='5px 0px'))\n",
        "pupil_label = widgets.HTML(value=\"<b>Pupil Diameter:</b> 0.00 mm\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "gaze_label = widgets.HTML(value=\"<b>Gaze Deviation:</b> 0.00°\",\n",
        "                          layout=widgets.Layout(margin='5px 0px'))\n",
        "latency_label = widgets.HTML(value=\"<b>Saccadic Latency:</b> 0.00 ms\",\n",
        "                             layout=widgets.Layout(margin='5px 0px'))\n",
        "smooth_pursuit_label = widgets.HTML(value=\"<b>Smooth Pursuit Gain:</b> 0.00\",\n",
        "                                    layout=widgets.Layout(margin='5px 0px'))\n",
        "search_time_label = widgets.HTML(value=\"<b>Microsaccades:</b> 0\",\n",
        "                                 layout=widgets.Layout(margin='5px 0px'))\n",
        "\n",
        "# Additional Labels for New Features with enhanced styling\n",
        "head_pose_label = widgets.HTML(value=\"<b>Head Pose:</b> Yaw: 0.00°, Pitch: 0.00°, Roll: 0.00°\",\n",
        "                               layout=widgets.Layout(margin='5px 0px'))\n",
        "eye_openness_label = widgets.HTML(value=\"<b>Eye Openness:</b> Left: 0.00, Right: 0.00\",\n",
        "                                   layout=widgets.Layout(margin='5px 0px'))\n",
        "pcr_ratio_label = widgets.HTML(value=\"<b>PCR Ratio:</b> 0.00\",\n",
        "                                layout=widgets.Layout(margin='5px 0px'))\n",
        "pupil_deformation_label = widgets.HTML(value=\"<b>Pupil Shape Deformation:</b> 0.00\",\n",
        "                                       layout=widgets.Layout(margin='5px 0px'))\n",
        "gaze_direction_label = widgets.HTML(value=\"<b>3D Gaze Direction:</b> 0.00°\",\n",
        "                                     layout=widgets.Layout(margin='5px 0px'))\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\",\n",
        "                             button_style='danger',\n",
        "                             tooltip='Click to stop the video stream and save data',\n",
        "                             layout=widgets.Layout(width='150px', height='40px'))\n",
        "\n",
        "# Organize metrics into sections using Tabs\n",
        "metrics_tab = widgets.Tab()\n",
        "metrics_tab.children = [\n",
        "    widgets.VBox([\n",
        "        speed_label,\n",
        "        blink_label,\n",
        "        fixation_label,\n",
        "        pupil_label,\n",
        "        gaze_label,\n",
        "        latency_label,\n",
        "        smooth_pursuit_label,\n",
        "        search_time_label\n",
        "    ], layout=widgets.Layout(padding='10px')),\n",
        "    widgets.VBox([\n",
        "        head_pose_label,\n",
        "        eye_openness_label,\n",
        "        pcr_ratio_label,\n",
        "        pupil_deformation_label,\n",
        "        gaze_direction_label\n",
        "    ], layout=widgets.Layout(padding='10px'))\n",
        "]\n",
        "\n",
        "# Set tab titles\n",
        "metrics_tab.set_title(0, 'Performance Metrics')\n",
        "metrics_tab.set_title(1, 'Additional Features')\n",
        "\n",
        "# Arrange the widgets in the notebook using Grids for better layout\n",
        "images_box = widgets.HBox([face_image, yellow_dot_image], layout=widgets.Layout(justify_content='space-between', width='100%'))\n",
        "graphs_box = widgets.HBox([saccade_speed_fig, blink_count_fig], layout=widgets.Layout(justify_content='space-between', width='100%'))\n",
        "\n",
        "controls_box = widgets.VBox([\n",
        "    metrics_tab,\n",
        "    graphs_box,\n",
        "    stop_button\n",
        "], layout=widgets.Layout(padding='10px'))\n",
        "\n",
        "# Combine all into a main VBox with a header\n",
        "main_box = widgets.VBox([\n",
        "    widgets.HTML(value=\"<h2 style='text-align: center; color: #4CAF50;'>Eye Movement Tracking Dashboard</h2>\"),\n",
        "    images_box,\n",
        "    controls_box\n",
        "], layout=widgets.Layout(align_items='center', padding='20px'))\n",
        "\n",
        "display(main_box)\n",
        "\n",
        "# Process frames with additional features\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag\n",
        "    global fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global microsaccades, head_pose, eye_openness_left, eye_openness_right\n",
        "    global pupil_shape_deformation, previous_fixation_point\n",
        "    global saccade_start_time, saccadic_latency, smooth_pursuit_gain, search_time_start\n",
        "    global total_search_time, target_search_count\n",
        "\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Search Time in Serial Search\n",
        "                    if search_time_start is None:\n",
        "                        search_time_start = current_time\n",
        "                    else:\n",
        "                        total_search_time = (current_time - search_time_start) * 1000  # in ms\n",
        "\n",
        "                    # New Features Calculations\n",
        "                    microsaccades += detect_microsaccades(eye_center, previous_center)\n",
        "                    head_pose = estimate_head_pose(face_landmarks.landmark, width, height)\n",
        "                    eye_openness_left = calculate_eye_openness(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    eye_openness_right = calculate_eye_openness(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "                    pupil_shape_deformation = calculate_pupil_shape_deformation(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "                    pcr_ratio = calculate_pcr_ratio(face_landmarks.landmark, width, height)\n",
        "                    gaze_direction = calculate_3d_gaze_direction(face_landmarks.landmark)\n",
        "\n",
        "                    # Update fixation points and fixation duration\n",
        "                    if fixation_start_time is None:\n",
        "                        fixation_start_time = current_time\n",
        "                    elif math.sqrt(dx ** 2 + dy ** 2) < fixation_threshold:\n",
        "                        fixation_points.append(eye_center)\n",
        "                        fixation_duration = current_time - fixation_start_time\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"PCR_Ratio\": pcr_ratio,\n",
        "                        \"3D_Gaze_Direction_deg\": gaze_direction,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Head_Pose_Yaw\": head_pose[\"yaw\"],\n",
        "                        \"Head_Pose_Pitch\": head_pose[\"pitch\"],\n",
        "                        \"Eye_Openness_Left\": eye_openness_left,\n",
        "                        \"Eye_Openness_Right\": eye_openness_right,\n",
        "                        \"Pupil_Shape_Deformation\": pupil_shape_deformation,\n",
        "                        \"Microsaccades\": microsaccades\n",
        "                    })\n",
        "\n",
        "                    # Update Plotly graphs\n",
        "                    saccade_speed_fig.add_trace(go.Scatter(x=[timestamp], y=[speed], mode='lines+markers', marker=dict(color='blue'), name='Saccade Speed'))\n",
        "                    blink_count_fig.add_trace(go.Bar(x=[timestamp], y=[blink_count], marker_color='orange', name='Blink Count'))\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels for new features\n",
        "            speed_label.value = f\"<b>Saccade Speed:</b> {speed:.2f} pixels/sec ({speed_class})\"\n",
        "            blink_label.value = f\"<b>Blinks:</b> {blink_count}\"\n",
        "            fixation_label.value = f\"<b>Fixation Duration:</b> {fixation_duration:.2f} sec\"\n",
        "            pupil_label.value = f\"<b>Pupil Diameter:</b> {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"<b>Gaze Deviation:</b> {gaze_deviation:.2f}°\"\n",
        "            latency_label.value = f\"<b>Saccadic Latency:</b> {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"<b>Smooth Pursuit Gain:</b> {smooth_pursuit_gain:.2f}\"\n",
        "            search_time_label.value = f\"<b>Microsaccades:</b> {microsaccades}\"\n",
        "            head_pose_label.value = f\"<b>Head Pose:</b> Yaw: {head_pose['yaw']:.2f}°, Pitch: {head_pose['pitch']:.2f}°, Roll: {head_pose['roll']:.2f}°\"\n",
        "            eye_openness_label.value = f\"<b>Eye Openness:</b> Left: {eye_openness_left:.2f}, Right: {eye_openness_right:.2f}\"\n",
        "            pcr_ratio_label.value = f\"<b>PCR Ratio:</b> {pcr_ratio:.2f}\"\n",
        "            pupil_deformation_label.value = f\"<b>Pupil Shape Deformation:</b> {pupil_shape_deformation:.2f}\"\n",
        "            gaze_direction_label.value = f\"<b>3D Gaze Direction:</b> {gaze_direction:.2f}°\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "rpvimZuwymjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Jupyter widgets extension\n",
        "!jupyter nbextension enable --py widgetsnbextension\n"
      ],
      "metadata": {
        "id": "-Zeo2TinzVS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas scipy plotly\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
        "import numpy.linalg as la\n",
        "\n",
        "# Enable custom widget manager for Plotly in Colab\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "saccade_start_time = None\n",
        "saccadic_latency = 0\n",
        "smooth_pursuit_gain = 0\n",
        "search_time_start = None\n",
        "total_search_time = 0\n",
        "target_search_count = 0\n",
        "\n",
        "# Initialize variables for new features\n",
        "head_pose = {\"yaw\": 0, \"pitch\": 0, \"roll\": 0}\n",
        "fixation_points = []\n",
        "microsaccades = 0\n",
        "eye_openness_left = 0.0\n",
        "eye_openness_right = 0.0\n",
        "previous_fixation_point = None\n",
        "pupil_shape_deformation = 0.0\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "def calculate_smooth_pursuit_gain(eye_center, previous_center, width, height):\n",
        "    if previous_center is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate movement distance\n",
        "    eye_movement = math.sqrt((eye_center[0] - previous_center[0])**2 + (eye_center[1] - previous_center[1])**2)\n",
        "    # Approximate target velocity using movement (can be improved with actual target data)\n",
        "    target_movement = math.sqrt(width**2 + height**2) / 60  # Assuming a screen-sized target moving at 60Hz\n",
        "    return eye_movement / target_movement\n",
        "\n",
        "# New Feature Functions\n",
        "def calculate_pcr_ratio(landmarks, width, height):\n",
        "    eye_top = landmarks[1]  # Assuming landmark 1 is the top reflection point\n",
        "    eye_bottom = landmarks[5]  # Assuming landmark 5 is the bottom reflection point\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    # Compute the PCR ratio\n",
        "    return vertical_distance / height  # Normalize by the frame height\n",
        "\n",
        "def calculate_3d_gaze_direction(landmarks):\n",
        "    eye_vector = np.array([landmarks[1].x - landmarks[5].x, landmarks[1].y - landmarks[5].y])\n",
        "    gaze_angle = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    return gaze_angle\n",
        "\n",
        "def calculate_eye_openness(landmarks, indices, width, height):\n",
        "    eye_top = landmarks[indices[1]]\n",
        "    eye_bottom = landmarks[indices[5]]\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    return vertical_distance\n",
        "\n",
        "def calculate_pupil_shape_deformation(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]\n",
        "    if len(iris_landmarks) < 4:\n",
        "        return 0.0\n",
        "    distances = [\n",
        "        math.dist(\n",
        "            (iris_landmarks[i].x * width, iris_landmarks[i].y * height),\n",
        "            (iris_landmarks[j].x * width, iris_landmarks[j].y * height)\n",
        "        )\n",
        "        for i in range(len(iris_landmarks))\n",
        "        for j in range(i+1, len(iris_landmarks))\n",
        "    ]\n",
        "    max_dist = max(distances)\n",
        "    min_dist = min(distances)\n",
        "    return max_dist / min_dist if min_dist > 0 else 0.0\n",
        "\n",
        "def estimate_head_pose(landmarks, width, height):\n",
        "    # Use specific landmarks to approximate head orientation\n",
        "    nose_tip = landmarks[1]  # Assuming 1 is the nose tip\n",
        "    left_eye = landmarks[33]  # Assuming 33 is the left eye corner\n",
        "    right_eye = landmarks[263]  # Assuming 263 is the right eye corner\n",
        "\n",
        "    eye_vector = np.array([left_eye.x - right_eye.x, left_eye.y - right_eye.y])\n",
        "    yaw = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    pitch = np.degrees(np.arctan2(\n",
        "        nose_tip.y - (left_eye.y + right_eye.y) / 2,\n",
        "        nose_tip.x - (left_eye.x + right_eye.x) / 2\n",
        "    ))\n",
        "\n",
        "    return {\"yaw\": yaw, \"pitch\": pitch, \"roll\": 0}  # Simplified roll estimation\n",
        "\n",
        "def detect_microsaccades(eye_center, previous_center):\n",
        "    if previous_center is None:\n",
        "        return 0\n",
        "    movement = math.sqrt(\n",
        "        (eye_center[0] - previous_center[0]) ** 2 +\n",
        "        (eye_center[1] - previous_center[1]) ** 2\n",
        "    )\n",
        "    if 0.1 < movement < 1.0:  # Threshold range for microsaccades\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for two real-time streams and info display\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "\n",
        "# Create Plotly real-time graphs\n",
        "saccade_speed_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='blue'), name='Saccade Speed')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Saccade Speed Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Speed (pixels/sec)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "blink_count_fig = go.FigureWidget(\n",
        "    data=[go.Bar(x=[], y=[], marker_color='orange', name='Blink Count')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Blink Count Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Blinks\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "fixation_duration_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='green'), name='Fixation Duration')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Fixation Duration Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Duration (sec)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "pupil_diameter_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='purple'), name='Pupil Diameter')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Pupil Diameter Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Diameter (mm)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create labels with enhanced styling\n",
        "speed_label = widgets.HTML(value=\"<b>Saccade Speed:</b> 0.00 pixels/sec (N/A)\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "blink_label = widgets.HTML(value=\"<b>Blinks:</b> 0\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "fixation_label = widgets.HTML(value=\"<b>Fixation Duration:</b> 0.00 sec\",\n",
        "                              layout=widgets.Layout(margin='5px 0px'))\n",
        "pupil_label = widgets.HTML(value=\"<b>Pupil Diameter:</b> 0.00 mm\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "gaze_label = widgets.HTML(value=\"<b>Gaze Deviation:</b> 0.00°\",\n",
        "                          layout=widgets.Layout(margin='5px 0px'))\n",
        "latency_label = widgets.HTML(value=\"<b>Saccadic Latency:</b> 0.00 ms\",\n",
        "                             layout=widgets.Layout(margin='5px 0px'))\n",
        "smooth_pursuit_label = widgets.HTML(value=\"<b>Smooth Pursuit Gain:</b> 0.00\",\n",
        "                                    layout=widgets.Layout(margin='5px 0px'))\n",
        "search_time_label = widgets.HTML(value=\"<b>Microsaccades:</b> 0\",\n",
        "                                 layout=widgets.Layout(margin='5px 0px'))\n",
        "\n",
        "# Additional Labels for New Features with enhanced styling\n",
        "head_pose_label = widgets.HTML(value=\"<b>Head Pose:</b> Yaw: 0.00°, Pitch: 0.00°, Roll: 0.00°\",\n",
        "                               layout=widgets.Layout(margin='5px 0px'))\n",
        "eye_openness_label = widgets.HTML(value=\"<b>Eye Openness:</b> Left: 0.00, Right: 0.00\",\n",
        "                                   layout=widgets.Layout(margin='5px 0px'))\n",
        "pcr_ratio_label = widgets.HTML(value=\"<b>PCR Ratio:</b> 0.00\",\n",
        "                                layout=widgets.Layout(margin='5px 0px'))\n",
        "pupil_deformation_label = widgets.HTML(value=\"<b>Pupil Shape Deformation:</b> 0.00\",\n",
        "                                       layout=widgets.Layout(margin='5px 0px'))\n",
        "gaze_direction_label = widgets.HTML(value=\"<b>3D Gaze Direction:</b> 0.00°\",\n",
        "                                     layout=widgets.Layout(margin='5px 0px'))\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\",\n",
        "                             button_style='danger',\n",
        "                             tooltip='Click to stop the video stream and save data',\n",
        "                             layout=widgets.Layout(width='150px', height='40px'))\n",
        "\n",
        "# Organize metrics into sections using Tabs\n",
        "metrics_tab = widgets.Tab()\n",
        "metrics_tab.children = [\n",
        "    widgets.VBox([\n",
        "        speed_label,\n",
        "        blink_label,\n",
        "        fixation_label,\n",
        "        pupil_label,\n",
        "        gaze_label,\n",
        "        latency_label,\n",
        "        smooth_pursuit_label,\n",
        "        search_time_label\n",
        "    ], layout=widgets.Layout(padding='10px')),\n",
        "    widgets.VBox([\n",
        "        head_pose_label,\n",
        "        eye_openness_label,\n",
        "        pcr_ratio_label,\n",
        "        pupil_deformation_label,\n",
        "        gaze_direction_label\n",
        "    ], layout=widgets.Layout(padding='10px'))\n",
        "]\n",
        "\n",
        "# Set tab titles\n",
        "metrics_tab.set_title(0, 'Performance Metrics')\n",
        "metrics_tab.set_title(1, 'Additional Features')\n",
        "\n",
        "# Arrange the widgets in the notebook using Grids for better layout\n",
        "images_box = widgets.HBox([face_image, yellow_dot_image], layout=widgets.Layout(justify_content='space-between', width='100%'))\n",
        "graphs_box = widgets.VBox([saccade_speed_fig, blink_count_fig, fixation_duration_fig, pupil_diameter_fig], layout=widgets.Layout(justify_content='space-between', width='100%'))\n",
        "\n",
        "controls_box = widgets.VBox([\n",
        "    metrics_tab,\n",
        "    graphs_box,\n",
        "    stop_button\n",
        "], layout=widgets.Layout(padding='10px'))\n",
        "\n",
        "# Combine all into a main VBox with a header\n",
        "main_box = widgets.VBox([\n",
        "    widgets.HTML(value=\"<h2 style='text-align: center; color: #4CAF50;'>Eye Movement Tracking Dashboard</h2>\"),\n",
        "    images_box,\n",
        "    controls_box\n",
        "], layout=widgets.Layout(align_items='center', padding='20px'))\n",
        "\n",
        "display(main_box)\n",
        "\n",
        "# Process frames with additional features\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag\n",
        "    global fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global microsaccades, head_pose, eye_openness_left, eye_openness_right\n",
        "    global pupil_shape_deformation, previous_fixation_point\n",
        "    global saccade_start_time, saccadic_latency, smooth_pursuit_gain, search_time_start\n",
        "    global total_search_time, target_search_count\n",
        "\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Search Time in Serial Search\n",
        "                    if search_time_start is None:\n",
        "                        search_time_start = current_time\n",
        "                    else:\n",
        "                        total_search_time = (current_time - search_time_start) * 1000  # in ms\n",
        "\n",
        "                    # New Features Calculations\n",
        "                    microsaccades += detect_microsaccades(eye_center, previous_center)\n",
        "                    head_pose = estimate_head_pose(face_landmarks.landmark, width, height)\n",
        "                    eye_openness_left = calculate_eye_openness(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    eye_openness_right = calculate_eye_openness(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "                    pupil_shape_deformation = calculate_pupil_shape_deformation(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "                    pcr_ratio = calculate_pcr_ratio(face_landmarks.landmark, width, height)\n",
        "                    gaze_direction = calculate_3d_gaze_direction(face_landmarks.landmark)\n",
        "\n",
        "                    # Update fixation points and fixation duration\n",
        "                    if fixation_start_time is None:\n",
        "                        fixation_start_time = current_time\n",
        "                    elif math.sqrt(dx ** 2 + dy ** 2) < fixation_threshold:\n",
        "                        fixation_points.append(eye_center)\n",
        "                        fixation_duration = current_time - fixation_start_time\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"PCR_Ratio\": pcr_ratio,\n",
        "                        \"3D_Gaze_Direction_deg\": gaze_direction,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Head_Pose_Yaw\": head_pose[\"yaw\"],\n",
        "                        \"Head_Pose_Pitch\": head_pose[\"pitch\"],\n",
        "                        \"Eye_Openness_Left\": eye_openness_left,\n",
        "                        \"Eye_Openness_Right\": eye_openness_right,\n",
        "                        \"Pupil_Shape_Deformation\": pupil_shape_deformation,\n",
        "                        \"Microsaccades\": microsaccades\n",
        "                    })\n",
        "\n",
        "                    # Update Plotly graphs\n",
        "                    saccade_speed_fig.add_trace(go.Scatter(x=[timestamp], y=[speed], mode='lines+markers', marker=dict(color='blue'), name='Saccade Speed'))\n",
        "                    blink_count_fig.add_trace(go.Bar(x=[timestamp], y=[blink_count], marker_color='orange', name='Blink Count'))\n",
        "                    fixation_duration_fig.add_trace(go.Scatter(x=[timestamp], y=[fixation_duration], mode='lines+markers', marker=dict(color='green'), name='Fixation Duration'))\n",
        "                    pupil_diameter_fig.add_trace(go.Scatter(x=[timestamp], y=[pupil_diameter], mode='lines+markers', marker=dict(color='purple'), name='Pupil Diameter'))\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels for all features\n",
        "            speed_label.value = f\"<b>Saccade Speed:</b> {speed:.2f} pixels/sec ({speed_class})\"\n",
        "            blink_label.value = f\"<b>Blinks:</b> {blink_count}\"\n",
        "            fixation_label.value = f\"<b>Fixation Duration:</b> {fixation_duration:.2f} sec\"\n",
        "            pupil_label.value = f\"<b>Pupil Diameter:</b> {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"<b>Gaze Deviation:</b> {gaze_deviation:.2f}°\"\n",
        "            latency_label.value = f\"<b>Saccadic Latency:</b> {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"<b>Smooth Pursuit Gain:</b> {smooth_pursuit_gain:.2f}\"\n",
        "            search_time_label.value = f\"<b>Microsaccades:</b> {microsaccades}\"\n",
        "            head_pose_label.value = f\"<b>Head Pose:</b> Yaw: {head_pose['yaw']:.2f}°, Pitch: {head_pose['pitch']:.2f}°, Roll: {head_pose['roll']:.2f}°\"\n",
        "            eye_openness_label.value = f\"<b>Eye Openness:</b> Left: {eye_openness_left:.2f}, Right: {eye_openness_right:.2f}\"\n",
        "            pcr_ratio_label.value = f\"<b>PCR Ratio:</b> {pcr_ratio:.2f}\"\n",
        "            pupil_deformation_label.value = f\"<b>Pupil Shape Deformation:</b> {pupil_shape_deformation:.2f}\"\n",
        "            gaze_direction_label.value = f\"<b>3D Gaze Direction:</b> {gaze_direction:.2f}°\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "NFpGejGy5VJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas scipy plotly\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
        "import numpy.linalg as la\n",
        "\n",
        "# Enable custom widget manager for Plotly in Colab\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,  # Increased confidence for better accuracy\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "yellow_dot_position = [112, 112]  # Starting at center of 224x224 frame\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection (lower threshold)\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "saccade_start_time = None\n",
        "saccadic_latency = 0\n",
        "smooth_pursuit_gain = 0\n",
        "search_time_start = None\n",
        "total_search_time = 0\n",
        "target_search_count = 0\n",
        "\n",
        "# Initialize variables for new features\n",
        "head_pose = {\"yaw\": 0, \"pitch\": 0, \"roll\": 0}\n",
        "fixation_points = []\n",
        "microsaccades = 0\n",
        "eye_openness_left = 0.0\n",
        "eye_openness_right = 0.0\n",
        "previous_fixation_point = None\n",
        "pupil_shape_deformation = 0.0\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "def calculate_smooth_pursuit_gain(eye_center, previous_center, width, height):\n",
        "    if previous_center is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate movement distance\n",
        "    eye_movement = math.sqrt((eye_center[0] - previous_center[0])**2 + (eye_center[1] - previous_center[1])**2)\n",
        "    # Approximate target velocity using movement (can be improved with actual target data)\n",
        "    target_movement = math.sqrt(width**2 + height**2) / 60  # Assuming a screen-sized target moving at 60Hz\n",
        "    return eye_movement / target_movement\n",
        "\n",
        "# New Feature Functions\n",
        "def calculate_pcr_ratio(landmarks, width, height):\n",
        "    eye_top = landmarks[1]  # Assuming landmark 1 is the top reflection point\n",
        "    eye_bottom = landmarks[5]  # Assuming landmark 5 is the bottom reflection point\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    # Compute the PCR ratio\n",
        "    return vertical_distance / height  # Normalize by the frame height\n",
        "\n",
        "def calculate_3d_gaze_direction(landmarks):\n",
        "    eye_vector = np.array([landmarks[1].x - landmarks[5].x, landmarks[1].y - landmarks[5].y])\n",
        "    gaze_angle = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    return gaze_angle\n",
        "\n",
        "def calculate_eye_openness(landmarks, indices, width, height):\n",
        "    eye_top = landmarks[indices[1]]\n",
        "    eye_bottom = landmarks[indices[5]]\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    return vertical_distance\n",
        "\n",
        "def calculate_pupil_shape_deformation(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]\n",
        "    if len(iris_landmarks) < 4:\n",
        "        return 0.0\n",
        "    distances = [\n",
        "        math.dist(\n",
        "            (iris_landmarks[i].x * width, iris_landmarks[i].y * height),\n",
        "            (iris_landmarks[j].x * width, iris_landmarks[j].y * height)\n",
        "        )\n",
        "        for i in range(len(iris_landmarks))\n",
        "        for j in range(i+1, len(iris_landmarks))\n",
        "    ]\n",
        "    max_dist = max(distances)\n",
        "    min_dist = min(distances)\n",
        "    return max_dist / min_dist if min_dist > 0 else 0.0\n",
        "\n",
        "def estimate_head_pose(landmarks, width, height):\n",
        "    # Use specific landmarks to approximate head orientation\n",
        "    nose_tip = landmarks[1]  # Assuming 1 is the nose tip\n",
        "    left_eye = landmarks[33]  # Assuming 33 is the left eye corner\n",
        "    right_eye = landmarks[263]  # Assuming 263 is the right eye corner\n",
        "\n",
        "    eye_vector = np.array([left_eye.x - right_eye.x, left_eye.y - right_eye.y])\n",
        "    yaw = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    pitch = np.degrees(np.arctan2(\n",
        "        nose_tip.y - (left_eye.y + right_eye.y) / 2,\n",
        "        nose_tip.x - (left_eye.x + right_eye.x) / 2\n",
        "    ))\n",
        "\n",
        "    return {\"yaw\": yaw, \"pitch\": pitch, \"roll\": 0}  # Simplified roll estimation\n",
        "\n",
        "def detect_microsaccades(eye_center, previous_center):\n",
        "    if previous_center is None:\n",
        "        return 0\n",
        "    movement = math.sqrt(\n",
        "        (eye_center[0] - previous_center[0]) ** 2 +\n",
        "        (eye_center[1] - previous_center[1]) ** 2\n",
        "    )\n",
        "    if 0.1 < movement < 1.0:  # Threshold range for microsaccades\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Output widgets for real-time streams\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "\n",
        "# Create Plotly real-time graphs\n",
        "saccade_speed_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='blue'), name='Saccade Speed')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Saccade Speed Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Speed (pixels/sec)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "blink_count_fig = go.FigureWidget(\n",
        "    data=[go.Bar(x=[], y=[], marker_color='orange', name='Blink Count')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Blink Count Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Blinks\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "fixation_duration_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='green'), name='Fixation Duration')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Fixation Duration Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Duration (sec)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "pupil_diameter_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='purple'), name='Pupil Diameter')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Pupil Diameter Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Diameter (mm)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create labels with enhanced styling\n",
        "speed_label = widgets.HTML(value=\"<b>Saccade Speed:</b> 0.00 pixels/sec (N/A)\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "blink_label = widgets.HTML(value=\"<b>Blinks:</b> 0\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "fixation_label = widgets.HTML(value=\"<b>Fixation Duration:</b> 0.00 sec\",\n",
        "                              layout=widgets.Layout(margin='5px 0px'))\n",
        "pupil_label = widgets.HTML(value=\"<b>Pupil Diameter:</b> 0.00 mm\",\n",
        "                           layout=widgets.Layout(margin='5px 0px'))\n",
        "gaze_label = widgets.HTML(value=\"<b>Gaze Deviation:</b> 0.00°\",\n",
        "                          layout=widgets.Layout(margin='5px 0px'))\n",
        "latency_label = widgets.HTML(value=\"<b>Saccadic Latency:</b> 0.00 ms\",\n",
        "                             layout=widgets.Layout(margin='5px 0px'))\n",
        "smooth_pursuit_label = widgets.HTML(value=\"<b>Smooth Pursuit Gain:</b> 0.00\",\n",
        "                                    layout=widgets.Layout(margin='5px 0px'))\n",
        "search_time_label = widgets.HTML(value=\"<b>Microsaccades:</b> 0\",\n",
        "                                 layout=widgets.Layout(margin='5px 0px'))\n",
        "\n",
        "# Additional Labels for New Features with enhanced styling\n",
        "head_pose_label = widgets.HTML(value=\"<b>Head Pose:</b> Yaw: 0.00°, Pitch: 0.00°, Roll: 0.00°\",\n",
        "                               layout=widgets.Layout(margin='5px 0px'))\n",
        "eye_openness_label = widgets.HTML(value=\"<b>Eye Openness:</b> Left: 0.00, Right: 0.00\",\n",
        "                                   layout=widgets.Layout(margin='5px 0px'))\n",
        "pcr_ratio_label = widgets.HTML(value=\"<b>PCR Ratio:</b> 0.00\",\n",
        "                                layout=widgets.Layout(margin='5px 0px'))\n",
        "pupil_deformation_label = widgets.HTML(value=\"<b>Pupil Shape Deformation:</b> 0.00\",\n",
        "                                       layout=widgets.Layout(margin='5px 0px'))\n",
        "gaze_direction_label = widgets.HTML(value=\"<b>3D Gaze Direction:</b> 0.00°\",\n",
        "                                     layout=widgets.Layout(margin='5px 0px'))\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\",\n",
        "                             button_style='danger',\n",
        "                             tooltip='Click to stop the video stream and save data',\n",
        "                             layout=widgets.Layout(width='150px', height='40px'))\n",
        "\n",
        "# Organize metrics into a grid layout\n",
        "metrics_grid = widgets.GridBox(\n",
        "    children=[\n",
        "        speed_label, blink_label, fixation_label, pupil_label,\n",
        "        gaze_label, latency_label, smooth_pursuit_label, search_time_label,\n",
        "        head_pose_label, eye_openness_label, pcr_ratio_label,\n",
        "        pupil_deformation_label, gaze_direction_label\n",
        "    ],\n",
        "    layout=widgets.Layout(\n",
        "        grid_template_columns='repeat(2, 300px)',\n",
        "        grid_template_rows='repeat(7, auto)',\n",
        "        grid_gap='10px 20px',\n",
        "        padding='10px'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Arrange the widgets in the notebook using Grids for better layout\n",
        "images_box = widgets.HBox([face_image, yellow_dot_image], layout=widgets.Layout(justify_content='space-between', width='100%'))\n",
        "metrics_and_graphs_box = widgets.VBox([\n",
        "    metrics_grid,\n",
        "    widgets.HBox([saccade_speed_fig, blink_count_fig]),\n",
        "    widgets.HBox([fixation_duration_fig, pupil_diameter_fig])\n",
        "], layout=widgets.Layout(justify_content='space-between', width='100%'))\n",
        "\n",
        "controls_box = widgets.HBox([\n",
        "    metrics_and_graphs_box,\n",
        "    stop_button\n",
        "], layout=widgets.Layout(justify_content='space-between', padding='10px'))\n",
        "\n",
        "# Combine all into a main VBox with a header\n",
        "main_box = widgets.VBox([\n",
        "    widgets.HTML(value=\"<h2 style='text-align: center; color: #4CAF50;'>Eye Movement Tracking Dashboard</h2>\"),\n",
        "    images_box,\n",
        "    controls_box\n",
        "], layout=widgets.Layout(align_items='center', padding='20px'))\n",
        "\n",
        "display(main_box)\n",
        "\n",
        "# Process frames with additional features\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, yellow_dot_position, blink_count, blink_flag\n",
        "    global fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global microsaccades, head_pose, eye_openness_left, eye_openness_right\n",
        "    global pupil_shape_deformation, previous_fixation_point\n",
        "    global saccade_start_time, saccadic_latency, smooth_pursuit_gain, search_time_start\n",
        "    global total_search_time, target_search_count\n",
        "\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "            speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "            blink_detected = False\n",
        "            pupil_diameter = 0.00\n",
        "            gaze_deviation = 0.00\n",
        "            fixation_info = \"Fixation Duration: 0.00 sec\"\n",
        "            dx, dy = 0, 0  # Initialize dx and dy\n",
        "            speed_class = \"N/A\"  # Initialize speed_class\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                        speed_info = f\"Saccade Speed: {speed:.2f} pixels/sec ({speed_class})\"\n",
        "                    else:\n",
        "                        speed_info = \"Saccade Speed: 0.00 pixels/sec (N/A)\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    # Using Iris landmarks for better estimation\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Search Time in Serial Search\n",
        "                    if search_time_start is None:\n",
        "                        search_time_start = current_time\n",
        "                    else:\n",
        "                        total_search_time = (current_time - search_time_start) * 1000  # in ms\n",
        "\n",
        "                    # New Features Calculations\n",
        "                    microsaccades += detect_microsaccades(eye_center, previous_center)\n",
        "                    head_pose = estimate_head_pose(face_landmarks.landmark, width, height)\n",
        "                    eye_openness_left = calculate_eye_openness(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    eye_openness_right = calculate_eye_openness(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "                    pupil_shape_deformation = calculate_pupil_shape_deformation(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "                    pcr_ratio = calculate_pcr_ratio(face_landmarks.landmark, width, height)\n",
        "                    gaze_direction = calculate_3d_gaze_direction(face_landmarks.landmark)\n",
        "\n",
        "                    # Update fixation points and fixation duration\n",
        "                    if fixation_start_time is None:\n",
        "                        fixation_start_time = current_time\n",
        "                    elif math.sqrt(dx ** 2 + dy ** 2) < fixation_threshold:\n",
        "                        fixation_points.append(eye_center)\n",
        "                        fixation_duration = current_time - fixation_start_time\n",
        "\n",
        "                    fixation_info = f\"Fixation Duration: {fixation_duration:.2f} sec\"\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Eye_Center_X\": eye_center[0],\n",
        "                        \"Eye_Center_Y\": eye_center[1],\n",
        "                        \"Yellow_Dot_X\": norm_x,\n",
        "                        \"Yellow_Dot_Y\": norm_y,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"PCR_Ratio\": pcr_ratio,\n",
        "                        \"3D_Gaze_Direction_deg\": gaze_direction,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Head_Pose_Yaw\": head_pose[\"yaw\"],\n",
        "                        \"Head_Pose_Pitch\": head_pose[\"pitch\"],\n",
        "                        \"Eye_Openness_Left\": eye_openness_left,\n",
        "                        \"Eye_Openness_Right\": eye_openness_right,\n",
        "                        \"Pupil_Shape_Deformation\": pupil_shape_deformation,\n",
        "                        \"Microsaccades\": microsaccades\n",
        "                    })\n",
        "\n",
        "                    # Update Plotly graphs\n",
        "                    saccade_speed_fig.add_trace(go.Scatter(x=[timestamp], y=[speed], mode='lines+markers', marker=dict(color='blue'), name='Saccade Speed'))\n",
        "                    blink_count_fig.add_trace(go.Bar(x=[timestamp], y=[blink_count], marker_color='orange', name='Blink Count'))\n",
        "                    fixation_duration_fig.add_trace(go.Scatter(x=[timestamp], y=[fixation_duration], mode='lines+markers', marker=dict(color='green'), name='Fixation Duration'))\n",
        "                    pupil_diameter_fig.add_trace(go.Scatter(x=[timestamp], y=[pupil_diameter], mode='lines+markers', marker=dict(color='purple'), name='Pupil Diameter'))\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels for all features\n",
        "            speed_label.value = f\"<b>Saccade Speed:</b> {speed:.2f} pixels/sec ({speed_class})\"\n",
        "            blink_label.value = f\"<b>Blinks:</b> {blink_count}\"\n",
        "            fixation_label.value = f\"<b>Fixation Duration:</b> {fixation_duration:.2f} sec\"\n",
        "            pupil_label.value = f\"<b>Pupil Diameter:</b> {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"<b>Gaze Deviation:</b> {gaze_deviation:.2f}°\"\n",
        "            latency_label.value = f\"<b>Saccadic Latency:</b> {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"<b>Smooth Pursuit Gain:</b> {smooth_pursuit_gain:.2f}\"\n",
        "            search_time_label.value = f\"<b>Microsaccades:</b> {microsaccades}\"\n",
        "            head_pose_label.value = f\"<b>Head Pose:</b> Yaw: {head_pose['yaw']:.2f}°, Pitch: {head_pose['pitch']:.2f}°, Roll: {head_pose['roll']:.2f}°\"\n",
        "            eye_openness_label.value = f\"<b>Eye Openness:</b> Left: {eye_openness_left:.2f}, Right: {eye_openness_right:.2f}\"\n",
        "            pcr_ratio_label.value = f\"<b>PCR Ratio:</b> {pcr_ratio:.2f}\"\n",
        "            pupil_deformation_label.value = f\"<b>Pupil Shape Deformation:</b> {pupil_shape_deformation:.2f}\"\n",
        "            gaze_direction_label.value = f\"<b>3D Gaze Direction:</b> {gaze_direction:.2f}°\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "W2ekk-4G5823"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install mediapipe opencv-python ipywidgets pandas scipy plotly\n",
        "\n",
        "# Import required libraries\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "import threading\n",
        "import time\n",
        "import math\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import atexit\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "# Suppress deprecated warnings from protobuf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='google.protobuf')\n",
        "\n",
        "# Enable custom widget manager for Plotly in Colab\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Define eye landmark indices for left and right eyes\n",
        "LEFT_EYE_INDICES = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_INDICES = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_IRIS_INDICES = [468, 469, 470, 471, 472, 473]\n",
        "RIGHT_IRIS_INDICES = [474, 475, 476, 477, 478, 479]\n",
        "\n",
        "# Initialize tracking variables\n",
        "previous_center = None\n",
        "speed = 0\n",
        "prev_time = time.time()\n",
        "frames = []\n",
        "lock = threading.Lock()\n",
        "blink_count = 0\n",
        "blink_threshold = 0.20  # EAR threshold for blink detection\n",
        "blink_flag = False\n",
        "fixation_start_time = None\n",
        "fixation_duration = 0\n",
        "fixation_threshold = 2  # pixels\n",
        "data_records = []\n",
        "is_streaming = True  # Flag to control video stream\n",
        "saccade_start_time = None\n",
        "saccadic_latency = 0\n",
        "smooth_pursuit_gain = 0\n",
        "microsaccades = 0\n",
        "head_pose = {\"yaw\": 0, \"pitch\": 0, \"roll\": 0}\n",
        "eye_openness_left = 0.0\n",
        "eye_openness_right = 0.0\n",
        "pcr_ratio = 0.0\n",
        "pupil_shape_deformation = 0.0\n",
        "gaze_direction = 0.0\n",
        "\n",
        "# Define helper functions\n",
        "def calculate_eye_center(landmarks, indices, width, height):\n",
        "    x = [landmarks[i].x for i in indices]\n",
        "    y = [landmarks[i].y for i in indices]\n",
        "    return (int(np.mean(x) * width), int(np.mean(y) * height))\n",
        "\n",
        "def calculate_pupil_diameter(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0  # Return 0 if iris landmarks are not available\n",
        "\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]  # Ensure valid indices\n",
        "    if len(iris_landmarks) < 2:\n",
        "        return 0.0  # Return 0 if not enough landmarks for calculation\n",
        "\n",
        "    center_x = np.mean([lm.x for lm in iris_landmarks]) * width\n",
        "    center_y = np.mean([lm.y for lm in iris_landmarks]) * height\n",
        "    distances = [math.sqrt((lm.x * width - center_x)**2 + (lm.y * height - center_y)**2) for lm in iris_landmarks]\n",
        "    diameter = 2 * np.mean(distances)\n",
        "    return diameter\n",
        "\n",
        "def classify_speed(speed):\n",
        "    if speed < 5:\n",
        "        return \"Very Slow\"\n",
        "    elif speed < 25:\n",
        "        return \"Slow\"\n",
        "    elif speed < 50:\n",
        "        return \"Normal\"\n",
        "    elif speed < 100:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def calculate_gaze_deviation(eye_center, width, height):\n",
        "    center_x, center_y = width / 2, height / 2\n",
        "    dx = eye_center[0] - center_x\n",
        "    dy = eye_center[1] - center_y\n",
        "    angle = math.degrees(math.atan2(dy, dx))\n",
        "    return angle\n",
        "\n",
        "def detect_blink(landmarks, width, height):\n",
        "    # Eye Aspect Ratio (EAR) calculation\n",
        "    def eye_aspect_ratio(eye):\n",
        "        # Compute the distances between the vertical eye landmarks\n",
        "        A = math.dist((eye[1].x * width, eye[1].y * height), (eye[5].x * width, eye[5].y * height))\n",
        "        B = math.dist((eye[2].x * width, eye[2].y * height), (eye[4].x * width, eye[4].y * height))\n",
        "        # Compute the distance between the horizontal eye landmarks\n",
        "        C = math.dist((eye[0].x * width, eye[0].y * height), (eye[3].x * width, eye[3].y * height))\n",
        "        # Compute EAR\n",
        "        ear = (A + B) / (2.0 * C)\n",
        "        return ear\n",
        "\n",
        "    # Left eye EAR\n",
        "    left_eye = [landmarks[i] for i in LEFT_EYE_INDICES if i < len(landmarks)]\n",
        "    right_eye = [landmarks[i] for i in RIGHT_EYE_INDICES if i < len(landmarks)]\n",
        "\n",
        "    if len(left_eye) == 6 and len(right_eye) == 6:\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "        return avg_ear < blink_threshold\n",
        "    return False\n",
        "\n",
        "def calculate_smooth_pursuit_gain(eye_center, previous_center, width, height):\n",
        "    if previous_center is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate movement distance\n",
        "    eye_movement = math.sqrt((eye_center[0] - previous_center[0])**2 + (eye_center[1] - previous_center[1])**2)\n",
        "    # Approximate target velocity using movement (can be improved with actual target data)\n",
        "    target_movement = math.sqrt(width**2 + height**2) / 60  # Assuming a screen-sized target moving at 60Hz\n",
        "    return eye_movement / target_movement\n",
        "\n",
        "# New Feature Functions\n",
        "def calculate_pcr_ratio(landmarks, width, height):\n",
        "    eye_top = landmarks[1]  # Assuming landmark 1 is the top reflection point\n",
        "    eye_bottom = landmarks[5]  # Assuming landmark 5 is the bottom reflection point\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    # Compute the PCR ratio\n",
        "    return vertical_distance / height  # Normalize by the frame height\n",
        "\n",
        "def calculate_3d_gaze_direction(landmarks):\n",
        "    eye_vector = np.array([landmarks[1].x - landmarks[5].x, landmarks[1].y - landmarks[5].y])\n",
        "    gaze_angle = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    return gaze_angle\n",
        "\n",
        "def calculate_eye_openness(landmarks, indices, width, height):\n",
        "    eye_top = landmarks[indices[1]]\n",
        "    eye_bottom = landmarks[indices[5]]\n",
        "    vertical_distance = math.dist(\n",
        "        (eye_top.x * width, eye_top.y * height),\n",
        "        (eye_bottom.x * width, eye_bottom.y * height)\n",
        "    )\n",
        "    return vertical_distance\n",
        "\n",
        "def calculate_pupil_shape_deformation(landmarks, iris_indices, width, height):\n",
        "    if len(iris_indices) == 0:\n",
        "        return 0.0\n",
        "    iris_landmarks = [landmarks[i] for i in iris_indices if i < len(landmarks)]\n",
        "    if len(iris_landmarks) < 4:\n",
        "        return 0.0\n",
        "    distances = [\n",
        "        math.dist(\n",
        "            (iris_landmarks[i].x * width, iris_landmarks[i].y * height),\n",
        "            (iris_landmarks[j].x * width, iris_landmarks[j].y * height)\n",
        "        )\n",
        "        for i in range(len(iris_landmarks))\n",
        "        for j in range(i+1, len(iris_landmarks))\n",
        "    ]\n",
        "    max_dist = max(distances)\n",
        "    min_dist = min(distances)\n",
        "    return max_dist / min_dist if min_dist > 0 else 0.0\n",
        "\n",
        "def estimate_head_pose(landmarks, width, height):\n",
        "    # Use specific landmarks to approximate head orientation\n",
        "    nose_tip = landmarks[1]  # Assuming 1 is the nose tip\n",
        "    left_eye = landmarks[33]  # Assuming 33 is the left eye corner\n",
        "    right_eye = landmarks[263]  # Assuming 263 is the right eye corner\n",
        "\n",
        "    eye_vector = np.array([left_eye.x - right_eye.x, left_eye.y - right_eye.y])\n",
        "    yaw = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))\n",
        "    pitch = np.degrees(np.arctan2(\n",
        "        nose_tip.y - (left_eye.y + right_eye.y) / 2,\n",
        "        nose_tip.x - (left_eye.x + right_eye.x) / 2\n",
        "    ))\n",
        "\n",
        "    return {\"yaw\": yaw, \"pitch\": pitch, \"roll\": 0}  # Simplified roll estimation\n",
        "\n",
        "def detect_microsaccades(eye_center, previous_center):\n",
        "    if previous_center is None:\n",
        "        return 0\n",
        "    movement = math.sqrt(\n",
        "        (eye_center[0] - previous_center[0]) ** 2 +\n",
        "        (eye_center[1] - previous_center[1]) ** 2\n",
        "    )\n",
        "    if 0.1 < movement < 1.0:  # Threshold range for microsaccades\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# Define the callback function to receive frames from JavaScript\n",
        "def receive_frame(dataURL):\n",
        "    global frames\n",
        "    try:\n",
        "        header, encoded = dataURL.split(\",\", 1)\n",
        "        data = base64.b64decode(encoded)\n",
        "        img = Image.open(io.BytesIO(data))\n",
        "        img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        with lock:\n",
        "            frames.append(img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in receive_frame: {e}\")\n",
        "\n",
        "# Register the callback\n",
        "output.register_callback('notebook.receive_frame', receive_frame)\n",
        "\n",
        "# JavaScript code to capture video frames and send to Python\n",
        "def capture_video():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.autoplay = true;\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            // Function to send frames to Python\n",
        "            const sendFrame = () => {\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                const dataURL = canvas.toDataURL('image/jpeg');\n",
        "                google.colab.kernel.invokeFunction('notebook.receive_frame', [dataURL], {});\n",
        "                setTimeout(sendFrame, 50);  // Send frame every 50ms (20 FPS)\n",
        "            }\n",
        "\n",
        "            video.addEventListener('play', () => {\n",
        "                sendFrame();\n",
        "            });\n",
        "        }\n",
        "\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# Start capturing video\n",
        "capture_video()\n",
        "\n",
        "# Create Image widgets for real-time streams\n",
        "face_image = widgets.Image(format='jpeg', width=640, height=480)        # Face with mesh and eye movement\n",
        "yellow_dot_image = widgets.Image(format='jpeg', width=224, height=224)  # Yellow dot movement\n",
        "\n",
        "# Create Plotly real-time graphs with predefined traces\n",
        "saccade_speed_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='blue'), name='Saccade Speed')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Saccade Speed Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Speed (pixels/sec)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "blink_count_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='orange'), name='Blink Count')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Blink Count Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Blinks\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "fixation_duration_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='green'), name='Fixation Duration')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Fixation Duration Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Duration (sec)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "pupil_diameter_fig = go.FigureWidget(\n",
        "    data=[go.Scatter(x=[], y=[], mode='lines+markers', line=dict(color='purple'), name='Pupil Diameter')],\n",
        "    layout=go.Layout(\n",
        "        title=\"Pupil Diameter Over Time\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Diameter (mm)\",\n",
        "        height=300\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create labels for all 13 metrics with fixed width\n",
        "speed_label = widgets.HTML(value=\"<b>Saccade Speed:</b> 0.00 pixels/sec (N/A)\",\n",
        "                           layout=widgets.Layout(width='100%', margin='5px'))\n",
        "blink_label = widgets.HTML(value=\"<b>Blinks:</b> 0\",\n",
        "                           layout=widgets.Layout(width='100%', margin='5px'))\n",
        "fixation_label = widgets.HTML(value=\"<b>Fixation Duration:</b> 0.00 sec\",\n",
        "                              layout=widgets.Layout(width='100%', margin='5px'))\n",
        "pupil_label = widgets.HTML(value=\"<b>Pupil Diameter:</b> 0.00 mm\",\n",
        "                           layout=widgets.Layout(width='100%', margin='5px'))\n",
        "gaze_label = widgets.HTML(value=\"<b>Gaze Deviation:</b> 0.00°\",\n",
        "                          layout=widgets.Layout(width='100%', margin='5px'))\n",
        "latency_label = widgets.HTML(value=\"<b>Saccadic Latency:</b> 0.00 ms\",\n",
        "                             layout=widgets.Layout(width='100%', margin='5px'))\n",
        "smooth_pursuit_label = widgets.HTML(value=\"<b>Smooth Pursuit Gain:</b> 0.00\",\n",
        "                                    layout=widgets.Layout(width='100%', margin='5px'))\n",
        "microsaccades_label = widgets.HTML(value=\"<b>Microsaccades:</b> 0\",\n",
        "                                   layout=widgets.Layout(width='100%', margin='5px'))\n",
        "head_pose_label = widgets.HTML(value=\"<b>Head Pose:</b> Yaw: 0.00°, Pitch: 0.00°, Roll: 0.00°\",\n",
        "                               layout=widgets.Layout(width='100%', margin='5px'))\n",
        "eye_openness_label = widgets.HTML(value=\"<b>Eye Openness:</b> Left: 0.00, Right: 0.00\",\n",
        "                                   layout=widgets.Layout(width='100%', margin='5px'))\n",
        "pcr_ratio_label = widgets.HTML(value=\"<b>PCR Ratio:</b> 0.00\",\n",
        "                                layout=widgets.Layout(width='100%', margin='5px'))\n",
        "pupil_deformation_label = widgets.HTML(value=\"<b>Pupil Shape Deformation:</b> 0.00\",\n",
        "                                       layout=widgets.Layout(width='100%', margin='5px'))\n",
        "gaze_direction_label = widgets.HTML(value=\"<b>3D Gaze Direction:</b> 0.00°\",\n",
        "                                     layout=widgets.Layout(width='100%', margin='5px'))\n",
        "\n",
        "# Button to stop the video stream\n",
        "stop_button = widgets.Button(description=\"Stop Stream\",\n",
        "                             button_style='danger',\n",
        "                             tooltip='Click to stop the video stream and save data',\n",
        "                             layout=widgets.Layout(width='150px', height='40px', margin='10px'))\n",
        "\n",
        "# Organize metrics into multiple rows with two labels each\n",
        "metrics_row1 = widgets.HBox([speed_label, blink_label], layout=widgets.Layout(width='100%'))\n",
        "metrics_row2 = widgets.HBox([fixation_label, pupil_label], layout=widgets.Layout(width='100%'))\n",
        "metrics_row3 = widgets.HBox([gaze_label, latency_label], layout=widgets.Layout(width='100%'))\n",
        "metrics_row4 = widgets.HBox([smooth_pursuit_label, microsaccades_label], layout=widgets.Layout(width='100%'))\n",
        "metrics_row5 = widgets.HBox([head_pose_label, eye_openness_label], layout=widgets.Layout(width='100%'))\n",
        "metrics_row6 = widgets.HBox([pcr_ratio_label, pupil_deformation_label], layout=widgets.Layout(width='100%'))\n",
        "metrics_row7 = widgets.HBox([gaze_direction_label], layout=widgets.Layout(width='100%'))\n",
        "\n",
        "# Combine all metric rows into a single VBox\n",
        "metrics_box = widgets.VBox([\n",
        "    metrics_row1,\n",
        "    metrics_row2,\n",
        "    metrics_row3,\n",
        "    metrics_row4,\n",
        "    metrics_row5,\n",
        "    metrics_row6,\n",
        "    metrics_row7\n",
        "], layout=widgets.Layout(width='100%', justify_content='space-between'))\n",
        "\n",
        "# Arrange the Plotly graphs in a grid with two columns\n",
        "graphs_grid = widgets.GridBox(\n",
        "    children=[\n",
        "        widgets.Output(),  # Placeholder for saccade_speed_fig\n",
        "        widgets.Output(),  # Placeholder for blink_count_fig\n",
        "        widgets.Output(),  # Placeholder for fixation_duration_fig\n",
        "        widgets.Output()   # Placeholder for pupil_diameter_fig\n",
        "    ],\n",
        "    layout=widgets.Layout(\n",
        "        grid_template_columns='50% 50%',\n",
        "        grid_template_rows='50% 50%',\n",
        "        width='100%',\n",
        "        height='auto',\n",
        "        grid_gap='10px'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Display the Plotly figures inside the GridBox\n",
        "with graphs_grid.children[0]:\n",
        "    display(saccade_speed_fig)\n",
        "with graphs_grid.children[1]:\n",
        "    display(blink_count_fig)\n",
        "with graphs_grid.children[2]:\n",
        "    display(fixation_duration_fig)\n",
        "with graphs_grid.children[3]:\n",
        "    display(pupil_diameter_fig)\n",
        "\n",
        "# Arrange the images side by side\n",
        "images_box = widgets.HBox([face_image, yellow_dot_image],\n",
        "                          layout=widgets.Layout(justify_content='space-between', width='100%'))\n",
        "\n",
        "# Combine all controls\n",
        "controls_box = widgets.VBox([\n",
        "    metrics_box,\n",
        "    graphs_grid,\n",
        "    stop_button\n",
        "], layout=widgets.Layout(justify_content='space-between', padding='10px', width='100%'))\n",
        "\n",
        "# Combine all into a main VBox with a header\n",
        "main_box = widgets.VBox([\n",
        "    widgets.HTML(value=\"<h2 style='text-align: center; color: #4CAF50;'>Eye Movement Tracking Dashboard</h2>\"),\n",
        "    images_box,\n",
        "    controls_box\n",
        "], layout=widgets.Layout(align_items='center', padding='20px', width='100%'))\n",
        "\n",
        "display(main_box)\n",
        "\n",
        "# Process frames with all features\n",
        "def process_frames():\n",
        "    global previous_center, speed, prev_time, blink_count, blink_flag\n",
        "    global fixation_start_time, fixation_duration, data_records, is_streaming\n",
        "    global microsaccades, head_pose, eye_openness_left, eye_openness_right\n",
        "    global pcr_ratio, pupil_shape_deformation, gaze_direction\n",
        "    global saccade_start_time, saccadic_latency, smooth_pursuit_gain\n",
        "\n",
        "    amplification_factor = 30  # Increased amplification for clearer movement\n",
        "\n",
        "    while is_streaming:\n",
        "        with lock:\n",
        "            if len(frames) > 0:\n",
        "                frame = frames.pop(0)\n",
        "            else:\n",
        "                frame = None\n",
        "        if frame is not None:\n",
        "            height, width, _ = frame.shape\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(image_rgb)\n",
        "            yellow_dot_frame = np.ones((224, 224, 3), dtype=np.uint8) * 255  # White background\n",
        "\n",
        "            # Initialize dx and dy to handle cases where no face is detected\n",
        "            dx, dy = 0, 0\n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    # Draw face mesh on the original frame\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
        "                    )\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=frame,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
        "                    )\n",
        "\n",
        "                    # Calculate centers of left and right eyes\n",
        "                    left_center = calculate_eye_center(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    right_center = calculate_eye_center(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "\n",
        "                    # Calculate the overall eye center\n",
        "                    eye_center = ((left_center[0] + right_center[0]) // 2, (left_center[1] + right_center[1]) // 2)\n",
        "\n",
        "                    # Draw a yellow dot at the eye center in the face frame\n",
        "                    cv2.circle(frame, eye_center, 15, (0, 255, 255), -1)  # Increased radius for visibility\n",
        "\n",
        "                    # Calculate speed based on movement\n",
        "                    current_time = time.time()\n",
        "                    if previous_center is not None:\n",
        "                        dx = eye_center[0] - previous_center[0]\n",
        "                        dy = eye_center[1] - previous_center[1]\n",
        "                        dt = current_time - prev_time\n",
        "                        speed = math.sqrt(dx**2 + dy**2) / dt if dt > 0 else 0\n",
        "                        speed_class = classify_speed(speed)\n",
        "                    else:\n",
        "                        speed = 0.0\n",
        "                        speed_class = \"N/A\"\n",
        "\n",
        "                    # Update previous position and time\n",
        "                    previous_center = eye_center\n",
        "                    prev_time = current_time\n",
        "\n",
        "                    # Calculate Smooth Pursuit Gain\n",
        "                    smooth_pursuit_gain = calculate_smooth_pursuit_gain(eye_center, previous_center, width, height)\n",
        "\n",
        "                    # Draw the yellow dot on a separate frame (amplified)\n",
        "                    rel_x = (eye_center[0] - width / 2) * amplification_factor\n",
        "                    rel_y = (eye_center[1] - height / 2) * amplification_factor\n",
        "                    norm_x = 112 + rel_x  # Center of 224x224 frame is 112\n",
        "                    norm_y = 112 + rel_y\n",
        "                    norm_x = int(np.clip(norm_x, 0, 223))\n",
        "                    norm_y = int(np.clip(norm_y, 0, 223))\n",
        "                    cv2.circle(yellow_dot_frame, (norm_x, norm_y), 15, (0, 255, 255), -1)  # Increased radius\n",
        "\n",
        "                    # Pupil Diameter\n",
        "                    pupil_diameter = calculate_pupil_diameter(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "\n",
        "                    # Gaze Deviation\n",
        "                    gaze_deviation = calculate_gaze_deviation(eye_center, width, height)\n",
        "\n",
        "                    # Blink Detection\n",
        "                    blink_detected = detect_blink(face_landmarks.landmark, width, height)\n",
        "                    if blink_detected and not blink_flag:\n",
        "                        blink_count += 1\n",
        "                        blink_flag = True\n",
        "                    elif not blink_detected and blink_flag:\n",
        "                        blink_flag = False\n",
        "\n",
        "                    # Saccadic Latency\n",
        "                    if saccade_start_time is None:\n",
        "                        saccade_start_time = current_time\n",
        "                    else:\n",
        "                        saccadic_latency = (current_time - saccade_start_time) * 1000  # in ms\n",
        "                        saccade_start_time = None\n",
        "\n",
        "                    # Fixation Duration\n",
        "                    movement = math.sqrt(dx**2 + dy**2)\n",
        "                    if movement < fixation_threshold:\n",
        "                        if fixation_start_time is None:\n",
        "                            fixation_start_time = current_time\n",
        "                        else:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                    else:\n",
        "                        if fixation_start_time is not None:\n",
        "                            fixation_duration = current_time - fixation_start_time\n",
        "                            fixation_start_time = None\n",
        "\n",
        "                    # New Features Calculations\n",
        "                    microsaccades += detect_microsaccades(eye_center, previous_center)\n",
        "                    head_pose = estimate_head_pose(face_landmarks.landmark, width, height)\n",
        "                    eye_openness_left = calculate_eye_openness(face_landmarks.landmark, LEFT_EYE_INDICES, width, height)\n",
        "                    eye_openness_right = calculate_eye_openness(face_landmarks.landmark, RIGHT_EYE_INDICES, width, height)\n",
        "                    pcr_ratio = calculate_pcr_ratio(face_landmarks.landmark, width, height)\n",
        "                    pupil_shape_deformation = calculate_pupil_shape_deformation(face_landmarks.landmark, LEFT_IRIS_INDICES + RIGHT_IRIS_INDICES, width, height)\n",
        "                    gaze_direction = calculate_3d_gaze_direction(face_landmarks.landmark)\n",
        "\n",
        "                    # Data Recording\n",
        "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
        "                    data_records.append({\n",
        "                        \"Timestamp\": timestamp,\n",
        "                        \"Saccade_Speed_pixels_sec\": speed,\n",
        "                        \"Saccade_Speed_Class\": speed_class,\n",
        "                        \"Blink_Count\": blink_count,\n",
        "                        \"Fixation_Duration_sec\": fixation_duration,\n",
        "                        \"Pupil_Diameter_mm\": pupil_diameter,\n",
        "                        \"Gaze_Deviation_deg\": gaze_deviation,\n",
        "                        \"Saccadic_Latency_ms\": saccadic_latency,\n",
        "                        \"Smooth_Pursuit_Gain\": smooth_pursuit_gain,\n",
        "                        \"Microsaccades\": microsaccades,\n",
        "                        \"Head_Pose_Yaw_deg\": head_pose[\"yaw\"],\n",
        "                        \"Head_Pose_Pitch_deg\": head_pose[\"pitch\"],\n",
        "                        \"Head_Pose_Roll_deg\": head_pose[\"roll\"],\n",
        "                        \"Eye_Openness_Left\": eye_openness_left,\n",
        "                        \"Eye_Openness_Right\": eye_openness_right,\n",
        "                        \"PCR_Ratio\": pcr_ratio,\n",
        "                        \"Pupil_Shape_Deformation\": pupil_shape_deformation,\n",
        "                        \"3D_Gaze_Direction_deg\": gaze_direction\n",
        "                    })\n",
        "\n",
        "                    # Update Plotly graphs by appending data to existing traces\n",
        "                    saccade_speed_fig.data[0].x += (timestamp,)\n",
        "                    saccade_speed_fig.data[0].y += (speed,)\n",
        "                    blink_count_fig.data[0].x += (timestamp,)\n",
        "                    blink_count_fig.data[0].y += (blink_count,)\n",
        "                    fixation_duration_fig.data[0].x += (timestamp,)\n",
        "                    fixation_duration_fig.data[0].y += (fixation_duration,)\n",
        "                    pupil_diameter_fig.data[0].x += (timestamp,)\n",
        "                    pupil_diameter_fig.data[0].y += (pupil_diameter,)\n",
        "\n",
        "            # Encode the face frame as JPEG\n",
        "            _, encoded_face_frame = cv2.imencode('.jpg', frame)\n",
        "            face_image.value = encoded_face_frame.tobytes()\n",
        "\n",
        "            # Encode the yellow dot frame as JPEG\n",
        "            _, encoded_dot_frame = cv2.imencode('.jpg', yellow_dot_frame)\n",
        "            yellow_dot_image.value = encoded_dot_frame.tobytes()\n",
        "\n",
        "            # Update labels for all features\n",
        "            speed_label.value = f\"<b>Saccade Speed:</b> {speed:.2f} pixels/sec ({speed_class})\"\n",
        "            blink_label.value = f\"<b>Blinks:</b> {blink_count}\"\n",
        "            fixation_label.value = f\"<b>Fixation Duration:</b> {fixation_duration:.2f} sec\"\n",
        "            pupil_label.value = f\"<b>Pupil Diameter:</b> {pupil_diameter:.2f} mm\"\n",
        "            gaze_label.value = f\"<b>Gaze Deviation:</b> {gaze_deviation:.2f}°\"\n",
        "            latency_label.value = f\"<b>Saccadic Latency:</b> {saccadic_latency:.2f} ms\"\n",
        "            smooth_pursuit_label.value = f\"<b>Smooth Pursuit Gain:</b> {smooth_pursuit_gain:.2f}\"\n",
        "            microsaccades_label.value = f\"<b>Microsaccades:</b> {microsaccades}\"\n",
        "            head_pose_label.value = f\"<b>Head Pose:</b> Yaw: {head_pose['yaw']:.2f}°, Pitch: {head_pose['pitch']:.2f}°, Roll: {head_pose['roll']:.2f}°\"\n",
        "            eye_openness_label.value = f\"<b>Eye Openness:</b> Left: {eye_openness_left:.2f}, Right: {eye_openness_right:.2f}\"\n",
        "            pcr_ratio_label.value = f\"<b>PCR Ratio:</b> {pcr_ratio:.2f}\"\n",
        "            pupil_deformation_label.value = f\"<b>Pupil Shape Deformation:</b> {pupil_shape_deformation:.2f}\"\n",
        "            gaze_direction_label.value = f\"<b>3D Gaze Direction:</b> {gaze_direction:.2f}°\"\n",
        "\n",
        "        # Control frame rate (20 FPS)\n",
        "        time.sleep(0.05)\n",
        "\n",
        "# Button event handler to stop the stream\n",
        "def stop_stream(b):\n",
        "    global is_streaming\n",
        "    is_streaming = False\n",
        "    save_data()\n",
        "\n",
        "# Attach the event handler to the button\n",
        "stop_button.on_click(stop_stream)\n",
        "\n",
        "# Start processing frames in a separate thread\n",
        "processing_thread = threading.Thread(target=process_frames)\n",
        "processing_thread.daemon = True\n",
        "processing_thread.start()\n",
        "\n",
        "# Save data to CSV when the stop button is clicked\n",
        "def save_data():\n",
        "    global data_records\n",
        "    if data_records:\n",
        "        df = pd.DataFrame(data_records)\n",
        "        filename = f\"eye_movement_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "    else:\n",
        "        print(\"No data to save.\")\n",
        "\n",
        "# Automatically save data when the kernel is interrupted\n",
        "atexit.register(save_data)\n"
      ],
      "metadata": {
        "id": "soxeewXYXViU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}