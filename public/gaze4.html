<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye Movement Data Collection & Visual Search Task</title>
    <link rel="stylesheet" href="style.css">
    <!-- TensorFlow.js -->
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <!-- WebGazer for Eye Tracking -->
    <script defer src="https://cdn.jsdelivr.net/npm/webgazer"></script>
    <style>
        /* Basic Reset */
        body, html {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            height: 100%;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f0f2f5;
            color: #333;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            align-items: center;
        }

        /* Container */
        .container {
            width: 100%;
            max-width: 1200px;
            text-align: center;
            position: relative;
            padding: 20px;
            flex-grow: 1;
        }

        /* Header Styling */
        header h1 {
            font-size: 2.5em;
            font-weight: 700;
            color: #007BFF;
            margin: 0;
            padding-bottom: 10px;
            border-bottom: 3px solid #61dafb;
        }

        /* Central Camera Frame */
        #camera-frame {
            position: relative;
            margin: 20px auto;
            width: 250px;
            height: 250px;
            border-radius: 50%;
            overflow: hidden;
            border: 4px solid #61dafb;
            background-color: #ffffff;
            box-shadow: 0 0 15px rgba(0, 0, 0, 0.3);
            z-index: 10;
        }

        #webcamVideo {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        /* Task Container */
        #task-container {
            margin: 20px 0;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            gap: 10px;
        }

        .ring {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            border: 3px solid black;
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 1.5em;
            cursor: pointer;
            transition: transform 0.2s, background-color 0.2s;
        }

        .ring:hover {
            transform: scale(1.1);
        }

        .target-ring-upward {
            border-color: red;
            font-size: 2em;
        }

        .distractor-ring {
            border-color: black;
        }

        .target-ring-color {
            border-color: red;
            background-color: #ffcccc;
        }

        /* Calibration Message */
        #calibrationMessage {
            margin-top: 10px;
            color: #007BFF;
            font-size: 1.5em;
            text-shadow: 1px 1px 5px rgba(0, 0, 0, 0.3);
        }

        /* Footer Styling */
        footer {
            width: 100%;
            background: #ffffff;
            color: #777;
            padding: 15px;
            border-radius: 0 0 20px 20px;
            font-size: 1em;
            text-align: center;
            box-shadow: 0 -5px 15px rgba(0, 0, 0, 0.2);
            position: relative;
            margin-top: auto;
        }

        /* Start Button */
        #startButton {
            padding: 10px 20px;
            font-size: 1.2em;
            background-color: #28a745;
            color: #ffffff;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        #startButton:hover {
            background-color: #218838;
        }

        /* Trial Information */
        #trialInfo {
            margin-top: 15px;
            font-size: 1.2em;
            color: #555;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .ring {
                width: 40px;
                height: 40px;
                font-size: 1em;
            }

            #camera-frame {
                width: 200px;
                height: 200px;
            }

            #startButton {
                font-size: 1em;
                padding: 8px 16px;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <header>
            <h1>Eye Movement Data Collection & Visual Search Task</h1>
        </header>

        <!-- Central Camera Frame -->
        <div id="camera-frame">
            <video id="webcamVideo" autoplay playsinline></video>
        </div>

        <!-- Start Button -->
        <button id="startButton">Start Task</button>

        <!-- Trial Information -->
        <div id="trialInfo"></div>

        <!-- Task Container -->
        <div id="task-container">
            <!-- Dynamically generated visual search task will appear here -->
        </div>

        <!-- Calibration Message -->
        <div id="calibrationMessage">Press "Start Task" to begin.</div>
    </div>

    <footer>
        <p>&copy; 2024 Eye Movement Research</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const taskContainer = document.getElementById('task-container');
            const calibrationMessage = document.getElementById('calibrationMessage');
            const startButton = document.getElementById('startButton');
            const trialInfo = document.getElementById('trialInfo');
            const webcamVideo = document.getElementById('webcamVideo');

            const searchTimeLimit = 60000; // 60 seconds per trial
            const totalTrials = 20; // Total number of trials (10 serial + 10 pop-out)
            let currentTrial = 0;
            let trials = [];

            // Configuration based on the research paper
            const taskTypes = ['serial', 'popout'];
            const numberOfRingsOptions = [4, 48];
            const trialsPerCombination = 5; // 5 trials for each combination (2 tasks * 2 ring numbers)

            // Initialize trials
            for (let task of taskTypes) {
                for (let numRings of numberOfRingsOptions) {
                    for (let i = 0; i < trialsPerCombination; i++) {
                        trials.push({
                            taskType: task,
                            numberOfRings: numRings
                        });
                    }
                }
            }

            // Shuffle trials to randomize the order
            shuffleArray(trials);

            // Array to store collected gaze data
            let gazeData = [];

            let timer;
            let trialStartTime;

            // Start Button Event Listener
            startButton.addEventListener('click', function() {
                startButton.style.display = 'none';
                startCamera()
                    .then(() => {
                        calibrationMessage.textContent = 'Camera started. Preparing to start trials...';
                        setTimeout(startNextTrial, 2000); // Delay before starting
                    })
                    .catch(error => {
                        console.error('Error starting camera:', error);
                        calibrationMessage.textContent = 'Error: Unable to access camera.';
                        startButton.style.display = 'block';
                    });
            });

            // Start the camera
            async function startCamera() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    webcamVideo.srcObject = stream;
                    console.log("Camera started");
                } catch (error) {
                    throw error;
                }
            }

            // Stop the camera
            function stopCamera() {
                const stream = webcamVideo.srcObject;
                if (stream) {
                    const tracks = stream.getTracks();
                    tracks.forEach(track => track.stop());
                    webcamVideo.srcObject = null;
                    console.log("Camera stopped");
                }
            }

            // Start the next trial
            function startNextTrial() {
                if (currentTrial >= trials.length) {
                    endExperiment();
                    return;
                }

                const trial = trials[currentTrial];
                currentTrial++;

                trialInfo.textContent = `Trial ${currentTrial} of ${trials.length}: ${trial.taskType.toUpperCase()} Search with ${trial.numberOfRings} Rings`;

                createSearchTask(trial.taskType, trial.numberOfRings);
                calibrationMessage.textContent = 'Please find the target as quickly as possible.';
                trialStartTime = Date.now();

                startTimer();
            }

            // Create Search Task
            function createSearchTask(taskType, numberOfRings) {
                taskContainer.innerHTML = '';
                const targetPosition = Math.floor(Math.random() * numberOfRings);

                for (let i = 0; i < numberOfRings; i++) {
                    const ring = document.createElement('div');
                    ring.classList.add('ring');

                    if (taskType === 'serial') {
                        // Serial Search: Target has upward orientation, distractors downward
                        if (i === targetPosition) {
                            ring.classList.add('target-ring-upward');
                            ring.textContent = 'O'; // Upward
                            ring.style.transform = 'rotate(0deg)';
                        } else {
                            ring.classList.add('distractor-ring');
                            ring.textContent = 'C'; // Downward
                            ring.style.transform = 'rotate(180deg)';
                        }
                    } else if (taskType === 'popout') {
                        // Pop-out Search: Target has different color, distractors same color
                        if (i === targetPosition) {
                            ring.classList.add('target-ring-color');
                            ring.textContent = 'O'; // Red
                        } else {
                            ring.classList.add('distractor-ring');
                            ring.textContent = 'O'; // Black
                        }
                    }

                    taskContainer.appendChild(ring);
                    ring.addEventListener('click', onRingClick.bind(null, i === targetPosition));
                }
            }

            // Handle Ring Click
            function onRingClick(isTarget) {
                if (isTarget) {
                    clearTimeout(timer);
                    const reactionTime = Date.now() - trialStartTime;
                    calibrationMessage.textContent = `Correct! Reaction Time: ${reactionTime} ms. Preparing next trial...`;
                    
                    // Store trial data here (e.g., reactionTime, gazeData)
                    // Implement feature extraction and data storage
                    extractFeaturesAndStore();

                    setTimeout(startNextTrial, 2000);
                } else {
                    calibrationMessage.textContent = 'Incorrect target. Try again!';
                }
            }

            // Start Timer for Trial
            function startTimer() {
                timer = setTimeout(() => {
                    calibrationMessage.textContent = 'Time is up! Proceeding to the next trial...';
                    // Implement feature extraction and data storage even if time is up
                    extractFeaturesAndStore();

                    setTimeout(startNextTrial, 2000);
                }, searchTimeLimit);
            }

            // End Experiment
            function endExperiment() {
                taskContainer.innerHTML = '';
                calibrationMessage.textContent = 'Data Collection complete. Processing results...';
                trialInfo.textContent = '';
                stopCamera();

                // Process the collected gaze data to extract features
                const features = extractFeatures();

                // Load the TensorFlow.js model and make prediction
                makePrediction(features);
            }

            // Shuffle array in-place using Fisher-Yates algorithm
            function shuffleArray(array) {
                for (let i = array.length - 1; i > 0; i--) {
                    const j = Math.floor(Math.random() * (i + 1));
                    [array[i], array[j]] = [array[j], array[i]];
                }
            }

            // Initialize WebGazer for Eye Tracking
            webgazer.setGazeListener(function(data, elapsedTime) {
                if (data == null) {
                    return;
                }
                // Store gaze data with timestamp
                gazeData.push({
                    x: data.x,
                    y: data.y,
                    timestamp: elapsedTime,
                    pupilSize: data.pupil || null // Assuming WebGazer provides pupil size
                });
            }).begin();

            // Disable WebGazer’s built-in UI
            webgazer.showVideo(false).showFaceOverlay(false).showFaceFeedbackBox(false);

            // Feature Extraction Function
            function extractFeatures() {
                // Placeholder functions for feature extraction
                // Implement actual algorithms based on raw gazeData

                // 1. Pupil Size Modulation (30%)
                const pupilSizes = gazeData.map(d => d.pupilSize).filter(p => p !== null);
                const pupilSizeModulation = computePupilSizeModulation(pupilSizes);

                // 2. Saccadic Latency (15%)
                const saccadicLatency = computeSaccadicLatency(gazeData);

                // 3. Smooth Pursuit Gain (12%)
                const smoothPursuitGain = computeSmoothPursuitGain(gazeData);

                // 4. Saccadic Accuracy (10%)
                const saccadicAccuracy = computeSaccadicAccuracy(gazeData);

                // 5. Fixation Duration (8%)
                const fixationDuration = computeFixationDuration(gazeData);

                // 6. Search Time in Serial Search (12%)
                const searchTimeSerial = computeSearchTimeSerial(gazeData);

                // Return features as an array or object
                return [
                    pupilSizeModulation,
                    saccadicLatency,
                    smoothPursuitGain,
                    saccadicAccuracy,
                    fixationDuration,
                    searchTimeSerial
                ];
            }

            // Implement actual feature extraction algorithms
            // The following are placeholders and need to be implemented based on your data and requirements

            function computePupilSizeModulation(pupilSizes) {
                // Example: Calculate the average pupil size
                if (pupilSizes.length === 0) return 0;
                const sum = pupilSizes.reduce((a, b) => a + b, 0);
                return sum / pupilSizes.length;
            }

            function computeSaccadicLatency(gazeData) {
                // Example: Time between target appearance and first saccade
                // Needs implementation based on task timing and gaze data
                return 0; // Placeholder
            }

            function computeSmoothPursuitGain(gazeData) {
                // Example: Ratio of eye velocity to target velocity
                // Needs implementation based on movement data
                return 0; // Placeholder
            }

            function computeSaccadicAccuracy(gazeData) {
                // Example: Distance between saccade endpoints and target
                // Needs implementation based on target position and gaze data
                return 0; // Placeholder
            }

            function computeFixationDuration(gazeData) {
                // Example: Average duration of fixations
                // Needs implementation based on gaze data
                return 0; // Placeholder
            }

            function computeSearchTimeSerial(gazeData) {
                // Example: Total time taken to find target in serial search tasks
                // Needs implementation based on task type and gaze data
                return 0; // Placeholder
            }

            // Extract Features and Store (Called after each trial)
            function extractFeaturesAndStore() {
                // Depending on how you want to store data, implement here
                // For example, you can store intermediate data or log it
            }

            // Make Prediction using TensorFlow.js Model
            async function makePrediction(features) {
                try {
                    console.log("Loading model...");
                    const model = await tf.loadLayersModel('./model.json');
                    console.log('Model loaded successfully');

                    // Normalize or preprocess features as required by your model
                    const inputTensor = tf.tensor2d([features]);

                    // Make prediction
                    const prediction = model.predict(inputTensor);
                    const predictedValue = prediction.argMax(1).dataSync()[0]; // Assuming classification

                    console.log("Predicted value:", predictedValue);

                    // Redirect to gaze5.html with the prediction result
                    window.location.href = `gaze5.html?result=${predictedValue}`;
                } catch (error) {
                    console.error('Prediction error:', error);
                    window.location.href = 'gaze5.html?result=error';
                }
            }
        });
    </script>
</body>
</html>
